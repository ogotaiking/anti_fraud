{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import atecml.data\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(func_name: str):\n",
    "    \"\"\"Elapsed Time\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    print('[{}][{}] Begin ...'.format(strftime('%Y-%m-%d %H:%M:%S'), func_name))\n",
    "    yield\n",
    "    print('[{}][{}] End   ...[Elapsed: {:.2f}s]'.format(strftime('%Y-%m-%d %H:%M:%S'), func_name, time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = atecml.data.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "target = 'Fraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0905-1015 for Train\n",
    "#1015-11xx for Verification\n",
    "\n",
    "train_df = atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-10-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/297 [00:00<00:39,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-06-22 12:23:53][PreProcessing: fillna] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 297/297 [00:27<00:00, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-06-22 12:24:21][PreProcessing: fillna] End   ...[Elapsed: 27.44s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with atecml.data.timer('PreProcessing: fillna'):\n",
    "    for idx in tqdm(range(len(predictors))):\n",
    "        item = predictors[idx]\n",
    "        train_df[item].fillna(train_df[item].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with timer('PreProcessing: Normalization'):\n",
    "    scaled_features = StandardScaler().fit_transform(train_df[predictors].values)\n",
    "    scaled_features_df = pd.DataFrame(scaled_features, index=train_df.index, columns=predictors)\n",
    "'''    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build Models...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "model = {}\n",
    "\n",
    "#model[\"RandomForest\"] = RandomForestClassifier(n_estimators=1000, max_depth=50, n_jobs=-1)\n",
    "#model[\"ExtraTree\"] =ExtraTreesClassifier(n_estimators=1000, max_depth=50, n_jobs=-1)\n",
    "model[\"LightGBM\"] = LGBMClassifier(n_estimators=1000, max_depth=50)\n",
    "#model[\"GBDT\"] =GradientBoostingClassifier(n_estimators=1000, max_depth=50)\n",
    "model[\"XGBOOST\"] =XGBClassifier(n_estimators=10, max_depth=5,nthread=80)\n",
    "\n",
    "\n",
    "def model_train(df, predictors,model_name):\n",
    "    model_cache_name = './'+model_name+'.model'\n",
    "    if (os.path.exists(model_cache_name)):\n",
    "        clf = joblib.load(model_cache_name)\n",
    "    else:\n",
    "        params = model_name.split('__')\n",
    "        model_key = params[0]\n",
    "        target = params[1]\n",
    "        clf = model[model_key]\n",
    "        with atecml.data.timer('> {} <: OverSample for imbalance data'.format(model_key)):\n",
    "            X_resampled, y_resampled = SMOTE().fit_sample(df[predictors],df[target])\n",
    "        with atecml.data.timer('> {} <: Training...'.format(model_key)):\n",
    "            clf.fit(X_resampled,y_resampled)\n",
    "        joblib.dump(clf,model_cache_name)\n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model =[]\n",
    "for idx in range(0,2):\n",
    "    for item in model.keys():\n",
    "        for target in ['Normal','Fraud']:\n",
    "            train_id = item + '__'+target +'__'+str(idx) \n",
    "            train_model.append(train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XGBOOST__Normal__0',\n",
       " 'XGBOOST__Fraud__0',\n",
       " 'LightGBM__Normal__0',\n",
       " 'LightGBM__Fraud__0',\n",
       " 'XGBOOST__Normal__1',\n",
       " 'XGBOOST__Fraud__1',\n",
       " 'LightGBM__Normal__1',\n",
       " 'LightGBM__Fraud__1']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-06-22 12:40:18][[XGBOOST]: OverSample for imbalance data] Begin ...\n",
      "[2018-06-22 12:40:47][[XGBOOST]: OverSample for imbalance data] End   ...[Elapsed: 29.39s]\n",
      "[2018-06-22 12:40:47][[XGBOOST]: Training...] Begin ...\n",
      "[2018-06-22 12:41:08][[XGBOOST]: Training...] End   ...[Elapsed: 21.00s]\n"
     ]
    }
   ],
   "source": [
    "a = model_train(train_df,predictors,'XGBOOST__Normal__0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model_train(train_df,predictors,'XGBOOST__Normal__0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_list =[]\n",
    "with timer('Classification: Model Training'):\n",
    "    for train_id in tqdm(range(len(train_model))):\n",
    "        fit_model = model_train(train_df,predictors,train_id)\n",
    "        trained_model_list.append(fit_model)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_df = atecml.data.load_train()\n",
    "verify_data = atecml.data.filter_date(verify_df,start_date='2017-10-16',end_date='2018-10-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Validation: verify_data fillna'):\n",
    "    for idx in tqdm(range(len(predictors))):\n",
    "        item = predictors[idx]\n",
    "        verify_data[item].fillna(verify_data[item].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_df =pd.DataFrame()\n",
    "with timer('Validation: Modelfit'):\n",
    "    for idx in tqdm(range(len(trained_model_list))):\n",
    "        clf = trained_model_list[idx]\n",
    "        y_predict = clf.predict_proba(np.array(verify_data[predictors]))\n",
    "        verify_df[idx] = pd.DataFrame(y_predict)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_df['mean'] = (verify_df[0] +verify_df[1]+verify_df[2]+verify_df[3])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def performance(y_test,y_predict_proba):\n",
    "    \"\"\"\n",
    "    基于ROC的模型性能测量，并根据蚂蚁金服评分标准输出分数\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_test,y_predict_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_result = pd.DataFrame()\n",
    "    roc_result['fpr'] = pd.Series(fpr)\n",
    "    roc_result['tpr'] = pd.Series(tpr)\n",
    "    roc_result['thresholds'] = pd.Series(thresholds)\n",
    "    TPR1= float(roc_result[roc_result['fpr']<=0.001002].tail(1)['tpr'])\n",
    "    TPR2=float(roc_result[roc_result['fpr']<=0.005002].tail(1)['tpr'])\n",
    "    TPR3=float(roc_result[roc_result['fpr']<=0.010002].tail(1)['tpr'])\n",
    "    FINAL_SCORE = 0.4*TPR1 + 0.3*TPR2 + 0.3 * TPR3\n",
    "    print(FINAL_SCORE)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    return (FINAL_SCORE,roc_result,roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=performance(verify_data[target],verify_df['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=performance(verify_data[target],verify_df['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(clf_params,clf,X,y,n_split=5):\n",
    "    #consider use data.filter_date function replace Kflod to avoid future info.\n",
    "    kf = KFold(n_splits=n_split, random_state=33, shuffle=True)\n",
    "    for train_index, test_index in tqdm(kf.split(X)):\n",
    "        X_, X_test = X[train_index], X[test_index]\n",
    "        y_, y_test = y[train_index], y[test_index]        \n",
    "        \n",
    "        # Divide into train and validation set for early-stop\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_, y_, test_size=0.15, random_state=42)\n",
    "        \n",
    "        del X_, y_\n",
    "        gc.collect()\n",
    "        \n",
    "        # Model Training\n",
    "        clf.fit(X=X_train, y=y_train, eval_set=[(X_valid, y_valid)], eval_metric='auc',\n",
    "                verbose=False, **clf_fit_params)\n",
    "        \n",
    "        ## Model Testing\n",
    "        # On training set\n",
    "        y_prob_train = clf.predict_proba(X_train)[:,1]\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        eval_train.iloc[i,:] = evaluate(y_train, y_pred_train, y_prob_train)\n",
    "        \n",
    "        # On testing set\n",
    "        y_prob_test = clf.predict_proba(X_test)[:,1]\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        eval_test.iloc[i,:] = evaluate(y_test, y_pred_test, y_prob_test)\n",
    "        \n",
    "        # Saving model\n",
    "        models.append(clf)\n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=33, shuffle=True)\n",
    "for train_index, test_index in tqdm(kf.split(train_df)):\n",
    "    X_ , X_test = X[train_index], X[test_index]\n",
    "    y_ , y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'boosting_type': 'gbdt',\n",
    "                      'num_leaves': 31,\n",
    "                      'max_depth': 50,\n",
    "                      'learning_rate': 0.10,\n",
    "                      'n_estimators': 100000,\n",
    "                      'reg_alpha': 0.1,\n",
    "                      'seed': 42,\n",
    "                      'nthread': -1}\n",
    "        \n",
    "        clf = lgb.LGBMClassifier(**lgb_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
