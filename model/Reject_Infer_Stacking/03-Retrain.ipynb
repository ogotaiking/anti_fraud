{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import atecml.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric o validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        model_list = []\n",
    "        \n",
    "        for i in range(0,n_folds):\n",
    "            \n",
    "            val_index = DateFold[5] #始终用最后20%验证            \n",
    "            train_index = list(all_list - DateFold[i])\n",
    "                            \n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            \n",
    "            #Over_sample\n",
    "            #X_resampled, y_resampled = SMOTE().fit_sample(x_tra,y_tra)\n",
    "            #model, auc = self.train(X_resampled, y_resampled, x_val, y_val)\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            model_list.append(model)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test,model_list\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    '''\n",
    "    ' 调参范围\n",
    "    'num_leaves':range(35,65,5)\n",
    "    'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7]\n",
    "    'min_child_weight':range(1,6,2)\n",
    "    'max_depth':range(3,10,2),\n",
    "    'subsample':[i/10.0 for i in range(6,10)],正常直接设置为1\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]，正常直接设置为1\n",
    "    'reg_alpha','reg_lambda':[1e-5, 1e-2, 0.1, 1, 2,2.5,3]\n",
    "    '''\n",
    "    def __init__(self,boost_type,boost_round=1000,early_stop=100):\n",
    "        self.num_boost_round = boost_round\n",
    "        self.early_stopping_rounds = early_stop\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': boost_type,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'learning_rate': 0.05,\n",
    "            'max_bin': 255,\n",
    "            'max_depth': 3,\n",
    "            'metric': {'auc'},\n",
    "            'min_child_samples': 800,\n",
    "            'min_child_weight': 0.05,\n",
    "            'min_split_gain': 0,\n",
    "            'nthread': 40,\n",
    "            'num_leaves': 31,\n",
    "            'objective': 'binary',\n",
    "            'reg_alpha': 1,\n",
    "            'reg_lambda': 2,\n",
    "            'is_unbalance':'true',\n",
    "            #'scale_pos_weight': 99,\n",
    "            'subsample': 0.85,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'subsample_freq': 1,\n",
    "            'use_missing': 'true',\n",
    "            'verbose' : -1,\n",
    "            }\n",
    "        print(self.params)\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets=lgbval, \n",
    "                          verbose_eval = 50,\n",
    "                          num_boost_round = self.num_boost_round,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "def stack_layer1_result(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        rf_input_list = []\n",
    "        for idx in tqdm(range(len(rf_model_list))):\n",
    "            model = rf_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            rf_input_list.append(pd.DataFrame(_temp_df))\n",
    "        rf_oof_predict= np.array(pd.concat(rf_input_list,ignore_index=True,axis=1).mean(axis=1))    \n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    input_predict = [rf_oof_predict, gbdt_oof_predict, dart_oof_predict] \n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('./train.dat')\n",
    "val_df = atecml.data.load_test()\n",
    "\n",
    "\n",
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "DateFold={}\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-12').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-13',end_date='2017-09-20').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-21',end_date='2017-09-28').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-09-29',end_date='2017-10-06').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-07',end_date='2017-10-14').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-15',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994731, 163) (994731,) (500538, 163)\n"
     ]
    }
   ],
   "source": [
    "target='Fraud'\n",
    "x_train = np.array(train_df[predictors])\n",
    "y_train = np.array(train_df[target])\n",
    "x_test = np.array(val_df[predictors])\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 3000\n",
    "num_early_stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_bin': 255, 'metric': {'auc'}, 'is_unbalance': 'true', 'num_leaves': 31, 'subsample_for_bin': 200000, 'subsample': 0.85, 'max_depth': 3, 'min_child_weight': 0.05, 'min_child_samples': 800, 'reg_lambda': 2, 'subsample_freq': 1, 'task': 'train', 'nthread': 40, 'objective': 'binary', 'verbose': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'min_split_gain': 0, 'boosting_type': 'rf', 'use_missing': 'true'}\n",
      "0 fold, train 831039, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.956912\n",
      "[100]\tvalid_0's auc: 0.956994\n",
      "[150]\tvalid_0's auc: 0.957007\n",
      "[200]\tvalid_0's auc: 0.956696\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.957279\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 837649, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.957077\n",
      "[100]\tvalid_0's auc: 0.958667\n",
      "[150]\tvalid_0's auc: 0.958558\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.958785\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 843385, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.955838\n",
      "[100]\tvalid_0's auc: 0.956193\n",
      "[150]\tvalid_0's auc: 0.956078\n",
      "[200]\tvalid_0's auc: 0.95591\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.956256\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 832567, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.956175\n",
      "[100]\tvalid_0's auc: 0.956284\n",
      "[150]\tvalid_0's auc: 0.958464\n",
      "[200]\tvalid_0's auc: 0.95805\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's auc: 0.958601\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 831094, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.955672\n",
      "[100]\tvalid_0's auc: 0.956978\n",
      "[150]\tvalid_0's auc: 0.95673\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.957513\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9572793584481153, 0.9587854272679256, 0.9562563833760281, 0.9586012589495913, 0.9575131073488677], average 0.9576871070781057\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "# get output of first layer models and construct as input for the second layer          \n",
    "rf_classifier = LGBClassifier(boost_type='rf',boost_round=num_boost_round,early_stop=num_early_stop)\n",
    "rf_oof_train, rf_oof_test,rf_model_list = rf_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(rf_oof_train.shape, rf_oof_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_bin': 255, 'metric': {'auc'}, 'is_unbalance': 'true', 'num_leaves': 31, 'subsample_for_bin': 200000, 'subsample': 0.85, 'max_depth': 3, 'min_child_weight': 0.05, 'min_child_samples': 800, 'reg_lambda': 2, 'subsample_freq': 1, 'task': 'train', 'nthread': 40, 'objective': 'binary', 'verbose': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'min_split_gain': 0, 'boosting_type': 'gbdt', 'use_missing': 'true'}\n",
      "0 fold, train 831039, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.973299\n",
      "[100]\tvalid_0's auc: 0.977882\n",
      "[150]\tvalid_0's auc: 0.980271\n",
      "[200]\tvalid_0's auc: 0.981843\n",
      "[250]\tvalid_0's auc: 0.982957\n",
      "[300]\tvalid_0's auc: 0.983973\n",
      "[350]\tvalid_0's auc: 0.984786\n",
      "[400]\tvalid_0's auc: 0.985416\n",
      "[450]\tvalid_0's auc: 0.985985\n",
      "[500]\tvalid_0's auc: 0.986441\n",
      "[550]\tvalid_0's auc: 0.986877\n",
      "[600]\tvalid_0's auc: 0.987199\n",
      "[650]\tvalid_0's auc: 0.987544\n",
      "[700]\tvalid_0's auc: 0.987793\n",
      "[750]\tvalid_0's auc: 0.988083\n",
      "[800]\tvalid_0's auc: 0.988334\n",
      "[850]\tvalid_0's auc: 0.988547\n",
      "[900]\tvalid_0's auc: 0.988774\n",
      "[950]\tvalid_0's auc: 0.989028\n",
      "[1000]\tvalid_0's auc: 0.989215\n",
      "[1050]\tvalid_0's auc: 0.989411\n",
      "[1100]\tvalid_0's auc: 0.989607\n",
      "[1150]\tvalid_0's auc: 0.98977\n",
      "[1200]\tvalid_0's auc: 0.989944\n",
      "[1250]\tvalid_0's auc: 0.990065\n",
      "[1300]\tvalid_0's auc: 0.990215\n",
      "[1350]\tvalid_0's auc: 0.990345\n",
      "[1400]\tvalid_0's auc: 0.990467\n",
      "[1450]\tvalid_0's auc: 0.99059\n",
      "[1500]\tvalid_0's auc: 0.990706\n",
      "[1550]\tvalid_0's auc: 0.990837\n",
      "[1600]\tvalid_0's auc: 0.990975\n",
      "[1650]\tvalid_0's auc: 0.991094\n",
      "[1700]\tvalid_0's auc: 0.991199\n",
      "[1750]\tvalid_0's auc: 0.991286\n",
      "[1800]\tvalid_0's auc: 0.991418\n",
      "[1850]\tvalid_0's auc: 0.991517\n",
      "[1900]\tvalid_0's auc: 0.991638\n",
      "[1950]\tvalid_0's auc: 0.991739\n",
      "[2000]\tvalid_0's auc: 0.991818\n",
      "[2050]\tvalid_0's auc: 0.991901\n",
      "[2100]\tvalid_0's auc: 0.991992\n",
      "[2150]\tvalid_0's auc: 0.992092\n",
      "[2200]\tvalid_0's auc: 0.992176\n",
      "[2250]\tvalid_0's auc: 0.992253\n",
      "[2300]\tvalid_0's auc: 0.99233\n",
      "[2350]\tvalid_0's auc: 0.99242\n",
      "[2400]\tvalid_0's auc: 0.992489\n",
      "[2450]\tvalid_0's auc: 0.992538\n",
      "[2500]\tvalid_0's auc: 0.992621\n",
      "[2550]\tvalid_0's auc: 0.992684\n",
      "[2600]\tvalid_0's auc: 0.992751\n",
      "[2650]\tvalid_0's auc: 0.992829\n",
      "[2700]\tvalid_0's auc: 0.992912\n",
      "[2750]\tvalid_0's auc: 0.992975\n",
      "[2800]\tvalid_0's auc: 0.993045\n",
      "[2850]\tvalid_0's auc: 0.993109\n",
      "[2900]\tvalid_0's auc: 0.99316\n",
      "[2950]\tvalid_0's auc: 0.993219\n",
      "[3000]\tvalid_0's auc: 0.993268\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.993268\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 837649, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.972146\n",
      "[100]\tvalid_0's auc: 0.977886\n",
      "[150]\tvalid_0's auc: 0.980489\n",
      "[200]\tvalid_0's auc: 0.98192\n",
      "[250]\tvalid_0's auc: 0.982992\n",
      "[300]\tvalid_0's auc: 0.984018\n",
      "[350]\tvalid_0's auc: 0.984755\n",
      "[400]\tvalid_0's auc: 0.985352\n",
      "[450]\tvalid_0's auc: 0.985871\n",
      "[500]\tvalid_0's auc: 0.986277\n",
      "[550]\tvalid_0's auc: 0.986746\n",
      "[600]\tvalid_0's auc: 0.98712\n",
      "[650]\tvalid_0's auc: 0.987452\n",
      "[700]\tvalid_0's auc: 0.987833\n",
      "[750]\tvalid_0's auc: 0.98808\n",
      "[800]\tvalid_0's auc: 0.98832\n",
      "[850]\tvalid_0's auc: 0.988548\n",
      "[900]\tvalid_0's auc: 0.988743\n",
      "[950]\tvalid_0's auc: 0.988946\n",
      "[1000]\tvalid_0's auc: 0.98915\n",
      "[1050]\tvalid_0's auc: 0.989346\n",
      "[1100]\tvalid_0's auc: 0.989512\n",
      "[1150]\tvalid_0's auc: 0.989676\n",
      "[1200]\tvalid_0's auc: 0.98981\n",
      "[1250]\tvalid_0's auc: 0.989958\n",
      "[1300]\tvalid_0's auc: 0.990097\n",
      "[1350]\tvalid_0's auc: 0.990246\n",
      "[1400]\tvalid_0's auc: 0.990371\n",
      "[1450]\tvalid_0's auc: 0.990462\n",
      "[1500]\tvalid_0's auc: 0.990569\n",
      "[1550]\tvalid_0's auc: 0.990713\n",
      "[1600]\tvalid_0's auc: 0.990816\n",
      "[1650]\tvalid_0's auc: 0.990926\n",
      "[1700]\tvalid_0's auc: 0.991007\n",
      "[1750]\tvalid_0's auc: 0.99113\n",
      "[1800]\tvalid_0's auc: 0.991238\n",
      "[1850]\tvalid_0's auc: 0.991336\n",
      "[1900]\tvalid_0's auc: 0.991431\n",
      "[1950]\tvalid_0's auc: 0.991544\n",
      "[2000]\tvalid_0's auc: 0.991636\n",
      "[2050]\tvalid_0's auc: 0.991721\n",
      "[2100]\tvalid_0's auc: 0.991804\n",
      "[2150]\tvalid_0's auc: 0.99188\n",
      "[2200]\tvalid_0's auc: 0.991961\n",
      "[2250]\tvalid_0's auc: 0.992053\n",
      "[2300]\tvalid_0's auc: 0.992139\n",
      "[2350]\tvalid_0's auc: 0.992228\n",
      "[2400]\tvalid_0's auc: 0.992298\n",
      "[2450]\tvalid_0's auc: 0.992369\n",
      "[2500]\tvalid_0's auc: 0.992432\n",
      "[2550]\tvalid_0's auc: 0.992485\n",
      "[2600]\tvalid_0's auc: 0.992586\n",
      "[2650]\tvalid_0's auc: 0.992647\n",
      "[2700]\tvalid_0's auc: 0.992713\n",
      "[2750]\tvalid_0's auc: 0.992771\n",
      "[2800]\tvalid_0's auc: 0.992846\n",
      "[2850]\tvalid_0's auc: 0.992913\n",
      "[2900]\tvalid_0's auc: 0.992964\n",
      "[2950]\tvalid_0's auc: 0.993022\n",
      "[3000]\tvalid_0's auc: 0.99307\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.99307\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 843385, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.972686\n",
      "[100]\tvalid_0's auc: 0.977873\n",
      "[150]\tvalid_0's auc: 0.980163\n",
      "[200]\tvalid_0's auc: 0.981766\n",
      "[250]\tvalid_0's auc: 0.982805\n",
      "[300]\tvalid_0's auc: 0.98361\n",
      "[350]\tvalid_0's auc: 0.984407\n",
      "[400]\tvalid_0's auc: 0.985115\n",
      "[450]\tvalid_0's auc: 0.985736\n",
      "[500]\tvalid_0's auc: 0.986169\n",
      "[550]\tvalid_0's auc: 0.9866\n",
      "[600]\tvalid_0's auc: 0.986985\n",
      "[650]\tvalid_0's auc: 0.987325\n",
      "[700]\tvalid_0's auc: 0.987701\n",
      "[750]\tvalid_0's auc: 0.987987\n",
      "[800]\tvalid_0's auc: 0.988237\n",
      "[850]\tvalid_0's auc: 0.988491\n",
      "[900]\tvalid_0's auc: 0.988677\n",
      "[950]\tvalid_0's auc: 0.988916\n",
      "[1000]\tvalid_0's auc: 0.989073\n",
      "[1050]\tvalid_0's auc: 0.989257\n",
      "[1100]\tvalid_0's auc: 0.989426\n",
      "[1150]\tvalid_0's auc: 0.989598\n",
      "[1200]\tvalid_0's auc: 0.989753\n",
      "[1250]\tvalid_0's auc: 0.989898\n",
      "[1300]\tvalid_0's auc: 0.990045\n",
      "[1350]\tvalid_0's auc: 0.990172\n",
      "[1400]\tvalid_0's auc: 0.99033\n",
      "[1450]\tvalid_0's auc: 0.990465\n",
      "[1500]\tvalid_0's auc: 0.990609\n",
      "[1550]\tvalid_0's auc: 0.990738\n",
      "[1600]\tvalid_0's auc: 0.990851\n",
      "[1650]\tvalid_0's auc: 0.99096\n",
      "[1700]\tvalid_0's auc: 0.991083\n",
      "[1750]\tvalid_0's auc: 0.991177\n",
      "[1800]\tvalid_0's auc: 0.991288\n",
      "[1850]\tvalid_0's auc: 0.991427\n",
      "[1900]\tvalid_0's auc: 0.991529\n",
      "[1950]\tvalid_0's auc: 0.991616\n",
      "[2000]\tvalid_0's auc: 0.991709\n",
      "[2050]\tvalid_0's auc: 0.991801\n",
      "[2100]\tvalid_0's auc: 0.991898\n",
      "[2150]\tvalid_0's auc: 0.992014\n",
      "[2200]\tvalid_0's auc: 0.992091\n",
      "[2250]\tvalid_0's auc: 0.992187\n",
      "[2300]\tvalid_0's auc: 0.992269\n",
      "[2350]\tvalid_0's auc: 0.992338\n",
      "[2400]\tvalid_0's auc: 0.992425\n",
      "[2450]\tvalid_0's auc: 0.992491\n",
      "[2500]\tvalid_0's auc: 0.992557\n",
      "[2550]\tvalid_0's auc: 0.992617\n",
      "[2600]\tvalid_0's auc: 0.992677\n",
      "[2650]\tvalid_0's auc: 0.992732\n",
      "[2700]\tvalid_0's auc: 0.992797\n",
      "[2750]\tvalid_0's auc: 0.992878\n",
      "[2800]\tvalid_0's auc: 0.992932\n",
      "[2850]\tvalid_0's auc: 0.992996\n",
      "[2900]\tvalid_0's auc: 0.993056\n",
      "[2950]\tvalid_0's auc: 0.993106\n",
      "[3000]\tvalid_0's auc: 0.99317\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.99317\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 832567, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.971739\n",
      "[100]\tvalid_0's auc: 0.977264\n",
      "[150]\tvalid_0's auc: 0.980182\n",
      "[200]\tvalid_0's auc: 0.981852\n",
      "[250]\tvalid_0's auc: 0.983031\n",
      "[300]\tvalid_0's auc: 0.984036\n",
      "[350]\tvalid_0's auc: 0.984814\n",
      "[400]\tvalid_0's auc: 0.985498\n",
      "[450]\tvalid_0's auc: 0.985977\n",
      "[500]\tvalid_0's auc: 0.986487\n",
      "[550]\tvalid_0's auc: 0.986898\n",
      "[600]\tvalid_0's auc: 0.98724\n",
      "[650]\tvalid_0's auc: 0.98756\n",
      "[700]\tvalid_0's auc: 0.987867\n",
      "[750]\tvalid_0's auc: 0.988152\n",
      "[800]\tvalid_0's auc: 0.98842\n",
      "[850]\tvalid_0's auc: 0.988708\n",
      "[900]\tvalid_0's auc: 0.988909\n",
      "[950]\tvalid_0's auc: 0.989073\n",
      "[1000]\tvalid_0's auc: 0.989281\n",
      "[1050]\tvalid_0's auc: 0.989453\n",
      "[1100]\tvalid_0's auc: 0.989596\n",
      "[1150]\tvalid_0's auc: 0.989758\n",
      "[1200]\tvalid_0's auc: 0.989891\n",
      "[1250]\tvalid_0's auc: 0.990028\n",
      "[1300]\tvalid_0's auc: 0.990144\n",
      "[1350]\tvalid_0's auc: 0.990285\n",
      "[1400]\tvalid_0's auc: 0.990403\n",
      "[1450]\tvalid_0's auc: 0.990547\n",
      "[1500]\tvalid_0's auc: 0.990631\n",
      "[1550]\tvalid_0's auc: 0.990747\n",
      "[1600]\tvalid_0's auc: 0.990864\n",
      "[1650]\tvalid_0's auc: 0.990958\n",
      "[1700]\tvalid_0's auc: 0.991043\n",
      "[1750]\tvalid_0's auc: 0.991151\n",
      "[1800]\tvalid_0's auc: 0.991256\n",
      "[1850]\tvalid_0's auc: 0.991364\n",
      "[1900]\tvalid_0's auc: 0.99146\n",
      "[1950]\tvalid_0's auc: 0.991551\n",
      "[2000]\tvalid_0's auc: 0.991638\n",
      "[2050]\tvalid_0's auc: 0.991719\n",
      "[2100]\tvalid_0's auc: 0.991804\n",
      "[2150]\tvalid_0's auc: 0.99188\n",
      "[2200]\tvalid_0's auc: 0.991976\n",
      "[2250]\tvalid_0's auc: 0.992043\n",
      "[2300]\tvalid_0's auc: 0.992134\n",
      "[2350]\tvalid_0's auc: 0.992216\n",
      "[2400]\tvalid_0's auc: 0.992292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2450]\tvalid_0's auc: 0.992347\n",
      "[2500]\tvalid_0's auc: 0.992418\n",
      "[2550]\tvalid_0's auc: 0.992504\n",
      "[2600]\tvalid_0's auc: 0.992576\n",
      "[2650]\tvalid_0's auc: 0.992635\n",
      "[2700]\tvalid_0's auc: 0.992717\n",
      "[2750]\tvalid_0's auc: 0.992784\n",
      "[2800]\tvalid_0's auc: 0.992838\n",
      "[2850]\tvalid_0's auc: 0.992901\n",
      "[2900]\tvalid_0's auc: 0.992965\n",
      "[2950]\tvalid_0's auc: 0.993023\n",
      "[3000]\tvalid_0's auc: 0.993075\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.993075\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 831094, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.971985\n",
      "[100]\tvalid_0's auc: 0.976945\n",
      "[150]\tvalid_0's auc: 0.979478\n",
      "[200]\tvalid_0's auc: 0.981174\n",
      "[250]\tvalid_0's auc: 0.98238\n",
      "[300]\tvalid_0's auc: 0.983406\n",
      "[350]\tvalid_0's auc: 0.984086\n",
      "[400]\tvalid_0's auc: 0.984811\n",
      "[450]\tvalid_0's auc: 0.985442\n",
      "[500]\tvalid_0's auc: 0.985866\n",
      "[550]\tvalid_0's auc: 0.986253\n",
      "[600]\tvalid_0's auc: 0.986684\n",
      "[650]\tvalid_0's auc: 0.987049\n",
      "[700]\tvalid_0's auc: 0.987394\n",
      "[750]\tvalid_0's auc: 0.987653\n",
      "[800]\tvalid_0's auc: 0.987896\n",
      "[850]\tvalid_0's auc: 0.988161\n",
      "[900]\tvalid_0's auc: 0.988369\n",
      "[950]\tvalid_0's auc: 0.988583\n",
      "[1000]\tvalid_0's auc: 0.988777\n",
      "[1050]\tvalid_0's auc: 0.988971\n",
      "[1100]\tvalid_0's auc: 0.98916\n",
      "[1150]\tvalid_0's auc: 0.989318\n",
      "[1200]\tvalid_0's auc: 0.989479\n",
      "[1250]\tvalid_0's auc: 0.989657\n",
      "[1300]\tvalid_0's auc: 0.989822\n",
      "[1350]\tvalid_0's auc: 0.989954\n",
      "[1400]\tvalid_0's auc: 0.99011\n",
      "[1450]\tvalid_0's auc: 0.990215\n",
      "[1500]\tvalid_0's auc: 0.990321\n",
      "[1550]\tvalid_0's auc: 0.990443\n",
      "[1600]\tvalid_0's auc: 0.990587\n",
      "[1650]\tvalid_0's auc: 0.990701\n",
      "[1700]\tvalid_0's auc: 0.990825\n",
      "[1750]\tvalid_0's auc: 0.990919\n",
      "[1800]\tvalid_0's auc: 0.991026\n",
      "[1850]\tvalid_0's auc: 0.991167\n",
      "[1900]\tvalid_0's auc: 0.991279\n",
      "[1950]\tvalid_0's auc: 0.991382\n",
      "[2000]\tvalid_0's auc: 0.991464\n",
      "[2050]\tvalid_0's auc: 0.991557\n",
      "[2100]\tvalid_0's auc: 0.991678\n",
      "[2150]\tvalid_0's auc: 0.991752\n",
      "[2200]\tvalid_0's auc: 0.991848\n",
      "[2250]\tvalid_0's auc: 0.991935\n",
      "[2300]\tvalid_0's auc: 0.992024\n",
      "[2350]\tvalid_0's auc: 0.992115\n",
      "[2400]\tvalid_0's auc: 0.992193\n",
      "[2450]\tvalid_0's auc: 0.992275\n",
      "[2500]\tvalid_0's auc: 0.992356\n",
      "[2550]\tvalid_0's auc: 0.99246\n",
      "[2600]\tvalid_0's auc: 0.992533\n",
      "[2650]\tvalid_0's auc: 0.9926\n",
      "[2700]\tvalid_0's auc: 0.992662\n",
      "[2750]\tvalid_0's auc: 0.99273\n",
      "[2800]\tvalid_0's auc: 0.992806\n",
      "[2850]\tvalid_0's auc: 0.992882\n",
      "[2900]\tvalid_0's auc: 0.992944\n",
      "[2950]\tvalid_0's auc: 0.993011\n",
      "[3000]\tvalid_0's auc: 0.993065\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.993065\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9932678186736478, 0.9930701270788109, 0.9931699296991886, 0.9930749228077047, 0.9930652848935269], average 0.9931296166305759\n",
      "(994731,) (500538,)\n",
      "{'max_bin': 255, 'metric': {'auc'}, 'is_unbalance': 'true', 'num_leaves': 31, 'subsample_for_bin': 200000, 'subsample': 0.85, 'max_depth': 3, 'min_child_weight': 0.05, 'min_child_samples': 800, 'reg_lambda': 2, 'subsample_freq': 1, 'task': 'train', 'nthread': 40, 'objective': 'binary', 'verbose': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'min_split_gain': 0, 'boosting_type': 'dart', 'use_missing': 'true'}\n",
      "0 fold, train 831039, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.972194\n",
      "[100]\tvalid_0's auc: 0.974056\n",
      "[150]\tvalid_0's auc: 0.974654\n",
      "[200]\tvalid_0's auc: 0.97643\n",
      "[250]\tvalid_0's auc: 0.977644\n",
      "[300]\tvalid_0's auc: 0.979028\n",
      "[350]\tvalid_0's auc: 0.979753\n",
      "[400]\tvalid_0's auc: 0.98083\n",
      "[450]\tvalid_0's auc: 0.981731\n",
      "[500]\tvalid_0's auc: 0.982306\n",
      "[550]\tvalid_0's auc: 0.982805\n",
      "[600]\tvalid_0's auc: 0.983003\n",
      "[650]\tvalid_0's auc: 0.983395\n",
      "[700]\tvalid_0's auc: 0.98376\n",
      "[750]\tvalid_0's auc: 0.984059\n",
      "[800]\tvalid_0's auc: 0.984308\n",
      "[850]\tvalid_0's auc: 0.984629\n",
      "[900]\tvalid_0's auc: 0.984976\n",
      "[950]\tvalid_0's auc: 0.985208\n",
      "[1000]\tvalid_0's auc: 0.985385\n",
      "[1050]\tvalid_0's auc: 0.985631\n",
      "[1100]\tvalid_0's auc: 0.985789\n",
      "[1150]\tvalid_0's auc: 0.985913\n",
      "[1200]\tvalid_0's auc: 0.986048\n",
      "[1250]\tvalid_0's auc: 0.9862\n",
      "[1300]\tvalid_0's auc: 0.986338\n",
      "[1350]\tvalid_0's auc: 0.986504\n",
      "[1400]\tvalid_0's auc: 0.986664\n",
      "[1450]\tvalid_0's auc: 0.986802\n",
      "[1500]\tvalid_0's auc: 0.986915\n",
      "[1550]\tvalid_0's auc: 0.987025\n",
      "[1600]\tvalid_0's auc: 0.987125\n",
      "[1650]\tvalid_0's auc: 0.987301\n",
      "[1700]\tvalid_0's auc: 0.987466\n",
      "[1750]\tvalid_0's auc: 0.987596\n",
      "[1800]\tvalid_0's auc: 0.98772\n",
      "[1850]\tvalid_0's auc: 0.987853\n",
      "[1900]\tvalid_0's auc: 0.987944\n",
      "[1950]\tvalid_0's auc: 0.988039\n",
      "[2000]\tvalid_0's auc: 0.988127\n",
      "[2050]\tvalid_0's auc: 0.988234\n",
      "[2100]\tvalid_0's auc: 0.988348\n",
      "[2150]\tvalid_0's auc: 0.988487\n",
      "[2200]\tvalid_0's auc: 0.988561\n",
      "[2250]\tvalid_0's auc: 0.988673\n",
      "[2300]\tvalid_0's auc: 0.988743\n",
      "[2350]\tvalid_0's auc: 0.988865\n",
      "[2400]\tvalid_0's auc: 0.988972\n",
      "[2450]\tvalid_0's auc: 0.989056\n",
      "[2500]\tvalid_0's auc: 0.989158\n",
      "[2550]\tvalid_0's auc: 0.989222\n",
      "[2600]\tvalid_0's auc: 0.989281\n",
      "[2650]\tvalid_0's auc: 0.98937\n",
      "[2700]\tvalid_0's auc: 0.989433\n",
      "[2750]\tvalid_0's auc: 0.989493\n",
      "[2800]\tvalid_0's auc: 0.989558\n",
      "[2850]\tvalid_0's auc: 0.989604\n",
      "[2900]\tvalid_0's auc: 0.98969\n",
      "[2950]\tvalid_0's auc: 0.989733\n",
      "[3000]\tvalid_0's auc: 0.989786\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989786\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 837649, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.970537\n",
      "[100]\tvalid_0's auc: 0.973605\n",
      "[150]\tvalid_0's auc: 0.974547\n",
      "[200]\tvalid_0's auc: 0.975855\n",
      "[250]\tvalid_0's auc: 0.977283\n",
      "[300]\tvalid_0's auc: 0.97881\n",
      "[350]\tvalid_0's auc: 0.979386\n",
      "[400]\tvalid_0's auc: 0.980392\n",
      "[450]\tvalid_0's auc: 0.981332\n",
      "[500]\tvalid_0's auc: 0.982029\n",
      "[550]\tvalid_0's auc: 0.982458\n",
      "[600]\tvalid_0's auc: 0.982739\n",
      "[650]\tvalid_0's auc: 0.983284\n",
      "[700]\tvalid_0's auc: 0.983683\n",
      "[750]\tvalid_0's auc: 0.984037\n",
      "[800]\tvalid_0's auc: 0.984248\n",
      "[850]\tvalid_0's auc: 0.984489\n",
      "[900]\tvalid_0's auc: 0.984846\n",
      "[950]\tvalid_0's auc: 0.984999\n",
      "[1000]\tvalid_0's auc: 0.985179\n",
      "[1050]\tvalid_0's auc: 0.985372\n",
      "[1100]\tvalid_0's auc: 0.985548\n",
      "[1150]\tvalid_0's auc: 0.98564\n",
      "[1200]\tvalid_0's auc: 0.985824\n",
      "[1250]\tvalid_0's auc: 0.985998\n",
      "[1300]\tvalid_0's auc: 0.986105\n",
      "[1350]\tvalid_0's auc: 0.986241\n",
      "[1400]\tvalid_0's auc: 0.986456\n",
      "[1450]\tvalid_0's auc: 0.986569\n",
      "[1500]\tvalid_0's auc: 0.986695\n",
      "[1550]\tvalid_0's auc: 0.986791\n",
      "[1600]\tvalid_0's auc: 0.986949\n",
      "[1650]\tvalid_0's auc: 0.987112\n",
      "[1700]\tvalid_0's auc: 0.987267\n",
      "[1750]\tvalid_0's auc: 0.987354\n",
      "[1800]\tvalid_0's auc: 0.9875\n",
      "[1850]\tvalid_0's auc: 0.987605\n",
      "[1900]\tvalid_0's auc: 0.987732\n",
      "[1950]\tvalid_0's auc: 0.987802\n",
      "[2000]\tvalid_0's auc: 0.987897\n",
      "[2050]\tvalid_0's auc: 0.988027\n",
      "[2100]\tvalid_0's auc: 0.988105\n",
      "[2150]\tvalid_0's auc: 0.988193\n",
      "[2200]\tvalid_0's auc: 0.988314\n",
      "[2250]\tvalid_0's auc: 0.988427\n",
      "[2300]\tvalid_0's auc: 0.98855\n",
      "[2350]\tvalid_0's auc: 0.988652\n",
      "[2400]\tvalid_0's auc: 0.988746\n",
      "[2450]\tvalid_0's auc: 0.988809\n",
      "[2500]\tvalid_0's auc: 0.98886\n",
      "[2550]\tvalid_0's auc: 0.988952\n",
      "[2600]\tvalid_0's auc: 0.989021\n",
      "[2650]\tvalid_0's auc: 0.989097\n",
      "[2700]\tvalid_0's auc: 0.989164\n",
      "[2750]\tvalid_0's auc: 0.989218\n",
      "[2800]\tvalid_0's auc: 0.989266\n",
      "[2850]\tvalid_0's auc: 0.98932\n",
      "[2900]\tvalid_0's auc: 0.989375\n",
      "[2950]\tvalid_0's auc: 0.989476\n",
      "[3000]\tvalid_0's auc: 0.989531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989531\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 843385, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.970828\n",
      "[100]\tvalid_0's auc: 0.973413\n",
      "[150]\tvalid_0's auc: 0.97447\n",
      "[200]\tvalid_0's auc: 0.976107\n",
      "[250]\tvalid_0's auc: 0.977431\n",
      "[300]\tvalid_0's auc: 0.978517\n",
      "[350]\tvalid_0's auc: 0.979315\n",
      "[400]\tvalid_0's auc: 0.980326\n",
      "[450]\tvalid_0's auc: 0.981105\n",
      "[500]\tvalid_0's auc: 0.981825\n",
      "[550]\tvalid_0's auc: 0.982291\n",
      "[600]\tvalid_0's auc: 0.982548\n",
      "[650]\tvalid_0's auc: 0.983038\n",
      "[700]\tvalid_0's auc: 0.983329\n",
      "[750]\tvalid_0's auc: 0.983633\n",
      "[800]\tvalid_0's auc: 0.983968\n",
      "[850]\tvalid_0's auc: 0.984317\n",
      "[900]\tvalid_0's auc: 0.984553\n",
      "[950]\tvalid_0's auc: 0.984722\n",
      "[1000]\tvalid_0's auc: 0.984899\n",
      "[1050]\tvalid_0's auc: 0.985159\n",
      "[1100]\tvalid_0's auc: 0.985339\n",
      "[1150]\tvalid_0's auc: 0.985534\n",
      "[1200]\tvalid_0's auc: 0.985676\n",
      "[1250]\tvalid_0's auc: 0.98587\n",
      "[1300]\tvalid_0's auc: 0.985947\n",
      "[1350]\tvalid_0's auc: 0.98607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400]\tvalid_0's auc: 0.986272\n",
      "[1450]\tvalid_0's auc: 0.986378\n",
      "[1500]\tvalid_0's auc: 0.986469\n",
      "[1550]\tvalid_0's auc: 0.986599\n",
      "[1600]\tvalid_0's auc: 0.986798\n",
      "[1650]\tvalid_0's auc: 0.98696\n",
      "[1700]\tvalid_0's auc: 0.987079\n",
      "[1750]\tvalid_0's auc: 0.987204\n",
      "[1800]\tvalid_0's auc: 0.987317\n",
      "[1850]\tvalid_0's auc: 0.987486\n",
      "[1900]\tvalid_0's auc: 0.987598\n",
      "[1950]\tvalid_0's auc: 0.987689\n",
      "[2000]\tvalid_0's auc: 0.987826\n",
      "[2050]\tvalid_0's auc: 0.987937\n",
      "[2100]\tvalid_0's auc: 0.988028\n",
      "[2150]\tvalid_0's auc: 0.988107\n",
      "[2200]\tvalid_0's auc: 0.988202\n",
      "[2250]\tvalid_0's auc: 0.988316\n",
      "[2300]\tvalid_0's auc: 0.988427\n",
      "[2350]\tvalid_0's auc: 0.988505\n",
      "[2400]\tvalid_0's auc: 0.98862\n",
      "[2450]\tvalid_0's auc: 0.988744\n",
      "[2500]\tvalid_0's auc: 0.988842\n",
      "[2550]\tvalid_0's auc: 0.988944\n",
      "[2600]\tvalid_0's auc: 0.989016\n",
      "[2650]\tvalid_0's auc: 0.989077\n",
      "[2700]\tvalid_0's auc: 0.989184\n",
      "[2750]\tvalid_0's auc: 0.989253\n",
      "[2800]\tvalid_0's auc: 0.989328\n",
      "[2850]\tvalid_0's auc: 0.989377\n",
      "[2900]\tvalid_0's auc: 0.989473\n",
      "[2950]\tvalid_0's auc: 0.989535\n",
      "[3000]\tvalid_0's auc: 0.989604\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989604\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 832567, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.969625\n",
      "[100]\tvalid_0's auc: 0.97274\n",
      "[150]\tvalid_0's auc: 0.974278\n",
      "[200]\tvalid_0's auc: 0.975879\n",
      "[250]\tvalid_0's auc: 0.977622\n",
      "[300]\tvalid_0's auc: 0.978838\n",
      "[350]\tvalid_0's auc: 0.979617\n",
      "[400]\tvalid_0's auc: 0.980679\n",
      "[450]\tvalid_0's auc: 0.981477\n",
      "[500]\tvalid_0's auc: 0.982152\n",
      "[550]\tvalid_0's auc: 0.982574\n",
      "[600]\tvalid_0's auc: 0.982942\n",
      "[650]\tvalid_0's auc: 0.983342\n",
      "[700]\tvalid_0's auc: 0.983669\n",
      "[750]\tvalid_0's auc: 0.983958\n",
      "[800]\tvalid_0's auc: 0.984205\n",
      "[850]\tvalid_0's auc: 0.984543\n",
      "[900]\tvalid_0's auc: 0.984837\n",
      "[950]\tvalid_0's auc: 0.985047\n",
      "[1000]\tvalid_0's auc: 0.985218\n",
      "[1050]\tvalid_0's auc: 0.985487\n",
      "[1100]\tvalid_0's auc: 0.985648\n",
      "[1150]\tvalid_0's auc: 0.98574\n",
      "[1200]\tvalid_0's auc: 0.985928\n",
      "[1250]\tvalid_0's auc: 0.986088\n",
      "[1300]\tvalid_0's auc: 0.986155\n",
      "[1350]\tvalid_0's auc: 0.986298\n",
      "[1400]\tvalid_0's auc: 0.986457\n",
      "[1450]\tvalid_0's auc: 0.986585\n",
      "[1500]\tvalid_0's auc: 0.98664\n",
      "[1550]\tvalid_0's auc: 0.98674\n",
      "[1600]\tvalid_0's auc: 0.986841\n",
      "[1650]\tvalid_0's auc: 0.986979\n",
      "[1700]\tvalid_0's auc: 0.987117\n",
      "[1750]\tvalid_0's auc: 0.987225\n",
      "[1800]\tvalid_0's auc: 0.987386\n",
      "[1850]\tvalid_0's auc: 0.987496\n",
      "[1900]\tvalid_0's auc: 0.987637\n",
      "[1950]\tvalid_0's auc: 0.987726\n",
      "[2000]\tvalid_0's auc: 0.987804\n",
      "[2050]\tvalid_0's auc: 0.987915\n",
      "[2100]\tvalid_0's auc: 0.988034\n",
      "[2150]\tvalid_0's auc: 0.988106\n",
      "[2200]\tvalid_0's auc: 0.988201\n",
      "[2250]\tvalid_0's auc: 0.988288\n",
      "[2300]\tvalid_0's auc: 0.988409\n",
      "[2350]\tvalid_0's auc: 0.988516\n",
      "[2400]\tvalid_0's auc: 0.988638\n",
      "[2450]\tvalid_0's auc: 0.988702\n",
      "[2500]\tvalid_0's auc: 0.988779\n",
      "[2550]\tvalid_0's auc: 0.988865\n",
      "[2600]\tvalid_0's auc: 0.98896\n",
      "[2650]\tvalid_0's auc: 0.989027\n",
      "[2700]\tvalid_0's auc: 0.989106\n",
      "[2750]\tvalid_0's auc: 0.989166\n",
      "[2800]\tvalid_0's auc: 0.989244\n",
      "[2850]\tvalid_0's auc: 0.989301\n",
      "[2900]\tvalid_0's auc: 0.989367\n",
      "[2950]\tvalid_0's auc: 0.989431\n",
      "[3000]\tvalid_0's auc: 0.98951\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.98951\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 831094, val 196810\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.970767\n",
      "[100]\tvalid_0's auc: 0.972975\n",
      "[150]\tvalid_0's auc: 0.974184\n",
      "[200]\tvalid_0's auc: 0.975793\n",
      "[250]\tvalid_0's auc: 0.977121\n",
      "[300]\tvalid_0's auc: 0.978602\n",
      "[350]\tvalid_0's auc: 0.97924\n",
      "[400]\tvalid_0's auc: 0.980271\n",
      "[450]\tvalid_0's auc: 0.981288\n",
      "[500]\tvalid_0's auc: 0.981865\n",
      "[550]\tvalid_0's auc: 0.982341\n",
      "[600]\tvalid_0's auc: 0.982638\n",
      "[650]\tvalid_0's auc: 0.983001\n",
      "[700]\tvalid_0's auc: 0.98329\n",
      "[750]\tvalid_0's auc: 0.983583\n",
      "[800]\tvalid_0's auc: 0.983822\n",
      "[850]\tvalid_0's auc: 0.984052\n",
      "[900]\tvalid_0's auc: 0.984227\n",
      "[950]\tvalid_0's auc: 0.98447\n",
      "[1000]\tvalid_0's auc: 0.984626\n",
      "[1050]\tvalid_0's auc: 0.984873\n",
      "[1100]\tvalid_0's auc: 0.985066\n",
      "[1150]\tvalid_0's auc: 0.985224\n",
      "[1200]\tvalid_0's auc: 0.985433\n",
      "[1250]\tvalid_0's auc: 0.985666\n",
      "[1300]\tvalid_0's auc: 0.985806\n",
      "[1350]\tvalid_0's auc: 0.985941\n",
      "[1400]\tvalid_0's auc: 0.986078\n",
      "[1450]\tvalid_0's auc: 0.986188\n",
      "[1500]\tvalid_0's auc: 0.986303\n",
      "[1550]\tvalid_0's auc: 0.986421\n",
      "[1600]\tvalid_0's auc: 0.986551\n",
      "[1650]\tvalid_0's auc: 0.986747\n",
      "[1700]\tvalid_0's auc: 0.986874\n",
      "[1750]\tvalid_0's auc: 0.986996\n",
      "[1800]\tvalid_0's auc: 0.987151\n",
      "[1850]\tvalid_0's auc: 0.987313\n",
      "[1900]\tvalid_0's auc: 0.98739\n",
      "[1950]\tvalid_0's auc: 0.987508\n",
      "[2000]\tvalid_0's auc: 0.987602\n",
      "[2050]\tvalid_0's auc: 0.987682\n",
      "[2100]\tvalid_0's auc: 0.987782\n",
      "[2150]\tvalid_0's auc: 0.987883\n",
      "[2200]\tvalid_0's auc: 0.987962\n",
      "[2250]\tvalid_0's auc: 0.988042\n",
      "[2300]\tvalid_0's auc: 0.988175\n",
      "[2350]\tvalid_0's auc: 0.988305\n",
      "[2400]\tvalid_0's auc: 0.988387\n",
      "[2450]\tvalid_0's auc: 0.988483\n",
      "[2500]\tvalid_0's auc: 0.988612\n",
      "[2550]\tvalid_0's auc: 0.988686\n",
      "[2600]\tvalid_0's auc: 0.98874\n",
      "[2650]\tvalid_0's auc: 0.988802\n",
      "[2700]\tvalid_0's auc: 0.98888\n",
      "[2750]\tvalid_0's auc: 0.988914\n",
      "[2800]\tvalid_0's auc: 0.988983\n",
      "[2850]\tvalid_0's auc: 0.989016\n",
      "[2900]\tvalid_0's auc: 0.989107\n",
      "[2950]\tvalid_0's auc: 0.989181\n",
      "[3000]\tvalid_0's auc: 0.989263\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989263\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9897863106826412, 0.9895310685542942, 0.9896038773318017, 0.9895103543646272, 0.9892628007688546], average 0.9895388823404436\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = LGBClassifier(boost_type='gbdt',boost_round=num_boost_round,early_stop=num_early_stop)\n",
    "gbdt_oof_train, gbdt_oof_test,gbdt_model_list = gbdt_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(gbdt_oof_train.shape, gbdt_oof_test.shape)  \n",
    "\n",
    "dart_classifier = LGBClassifier(boost_type='dart',boost_round=num_boost_round,early_stop=num_early_stop)\n",
    "dart_oof_train, dart_oof_test,dart_model_list = dart_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(dart_oof_train.shape, dart_oof_test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-02 20:51:17][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.79s/it]\n",
      "100%|██████████| 5/5 [00:44<00:00,  8.92s/it]\n",
      "100%|██████████| 5/5 [00:44<00:00,  8.89s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-02 20:53:01][Classification: Building Layer-1 Stack] End   ...[Elapsed: 103.98s]\n",
      "[2018-07-02 20:53:01][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.18s/it]\n",
      "100%|██████████| 5/5 [00:21<00:00,  4.36s/it]\n",
      "100%|██████████| 5/5 [00:21<00:00,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-02 20:53:51][Classification: Building Layer-1 Stack] End   ...[Elapsed: 49.94s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_train = stack_layer1_result(x_train,rf_model_list,gbdt_model_list,dart_model_list)\n",
    "stacked_test = stack_layer1_result(x_test,rf_model_list,gbdt_model_list,dart_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ant-Score: 0.5691700960219479\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCjMzK8tBYWZmZf1/SybezyjRhLkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use XGBOOST  as the model of the second layer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = pd.DataFrame(model.predict_proba(x_val))[1]\n",
    "\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "final_model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict_proba(stacked_test)\n",
    "\n",
    "result=pd.DataFrame()\n",
    "result['id'] = val_df['id']\n",
    "result['score'] = pd.DataFrame(test_prediction)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fdfd92f62e8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkqRuhoYkqdv/AzTdLCPYBIPkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13089"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[result.score > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fdfe401a9b0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAVJUstQkCS1/j8sCuwoNKMmMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[result.score > 0.1].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./submit_0702_night.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
