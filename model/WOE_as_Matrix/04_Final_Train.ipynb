{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step.2 KGB(known Good/Bad)训练，用于检测拒绝集(训练集中的unknown标签)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import atecml.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric o validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        model_list = []\n",
    "        \n",
    "        for i in range(0,n_folds):\n",
    "            \n",
    "            val_index = DateFold[5] #始终用最后20%验证            \n",
    "            train_index = list(all_list - DateFold[i])\n",
    "                            \n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            \n",
    "            #Over_sample\n",
    "            #X_resampled, y_resampled = SMOTE().fit_sample(x_tra,y_tra)\n",
    "            #model, auc = self.train(X_resampled, y_resampled, x_val, y_val)\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            model_list.append(model)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test,model_list\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    '''\n",
    "    ' 调参范围\n",
    "    'num_leaves':range(35,65,5)\n",
    "    'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7]\n",
    "    'min_child_weight':range(1,6,2)\n",
    "    'max_depth':range(3,10,2),\n",
    "    'subsample':[i/10.0 for i in range(6,10)],正常直接设置为1\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]，正常直接设置为1\n",
    "    'reg_alpha','reg_lambda':[1e-5, 1e-2, 0.1, 1, 2,2.5,3]\n",
    "    '''\n",
    "    def __init__(self,boost_type,boost_round=1000,early_stop=100,pos_weight=1):\n",
    "        self.num_boost_round = boost_round\n",
    "        self.early_stopping_rounds = early_stop\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': boost_type,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'learning_rate': 0.05,\n",
    "            'max_bin': 255,\n",
    "            'max_depth': -1,\n",
    "            'metric': {'auc'},\n",
    "            'min_child_samples': 600,\n",
    "            'min_child_weight': 0.05,\n",
    "            'min_split_gain': 0,\n",
    "            'nthread': 40,\n",
    "            'num_leaves': 80,\n",
    "            'objective': 'binary',\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            #'is_unbalance':'true',\n",
    "            'scale_pos_weight': pos_weight,\n",
    "            'subsample': 0.85,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'subsample_freq': 1,\n",
    "            'use_missing': 'true',\n",
    "            'verbose' : -1,\n",
    "            }\n",
    "        print(self.params)\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets=lgbval, \n",
    "                          verbose_eval = 50,\n",
    "                          num_boost_round = self.num_boost_round,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "def stack_layer1_result(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        rf_input_list = []\n",
    "        for idx in tqdm(range(len(rf_model_list))):\n",
    "            model = rf_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            rf_input_list.append(pd.DataFrame(_temp_df))\n",
    "        rf_oof_predict= np.array(pd.concat(rf_input_list,ignore_index=True,axis=1).mean(axis=1))    \n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    input_predict = [rf_oof_predict, gbdt_oof_predict, dart_oof_predict] \n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict\n",
    "\n",
    "def stack_layer1_result_wo_rf(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        predict_list = []\n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            predict_list.append(_temp_df)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            predict_list.append(_temp_df)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    #input_predict = [ gbdt_oof_predict, dart_oof_predict] \n",
    "    input_predict = predict_list\n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994731, 480) (994731,) (500538, 480)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_pickle('./train_new.dat')\n",
    "val_df = pd.read_pickle('./test_new.dat')\n",
    "target = 'Fraud'\n",
    "\n",
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "\n",
    "DateFold_DF = {}\n",
    "DateFold_DF[0] = atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-12')\n",
    "DateFold_DF[1] = atecml.data.filter_date(train_df,start_date='2017-09-13',end_date='2017-09-20')\n",
    "DateFold_DF[2] = atecml.data.filter_date(train_df,start_date='2017-09-21',end_date='2017-09-28')\n",
    "DateFold_DF[3] = atecml.data.filter_date(train_df,start_date='2017-09-29',end_date='2017-10-06')\n",
    "DateFold_DF[4] = atecml.data.filter_date(train_df,start_date='2017-10-07',end_date='2017-10-14')\n",
    "DateFold_DF[5] = atecml.data.filter_date(train_df,start_date='2017-10-15',end_date='2017-11-24')\n",
    "\n",
    "\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(DateFold_DF[0].index)\n",
    "DateFold[1] = set(DateFold_DF[1].index)\n",
    "DateFold[2] = set(DateFold_DF[2].index)\n",
    "DateFold[3] = set(DateFold_DF[3].index)\n",
    "DateFold[4] = set(DateFold_DF[4].index)\n",
    "DateFold[5] = list(DateFold_DF[4].index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])\n",
    "\n",
    "x_train = np.array(train_df[predictors])\n",
    "y_train = np.array(train_df[target])\n",
    "x_test = np.array(val_df[predictors])\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13189.0 981542.0 74.42126014102661\n"
     ]
    }
   ],
   "source": [
    "num_pos = np.sum(train_df[target])  \n",
    "num_neg = x_train.shape[0]- num_pos\n",
    "scale_pos_weight =  num_neg/num_pos\n",
    "print(num_pos,num_neg,scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 2500\n",
    "num_early_stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 1, 'boosting_type': 'rf', 'nthread': 40, 'subsample': 0.85, 'min_child_samples': 600, 'min_split_gain': 0, 'reg_lambda': 0.1, 'num_leaves': 80, 'max_bin': 255, 'task': 'train', 'min_child_weight': 0.05, 'learning_rate': 0.05, 'scale_pos_weight': 74.42126014102661, 'metric': {'auc'}, 'max_depth': -1, 'colsample_bytree': 0.7, 'subsample_for_bin': 200000, 'use_missing': 'true', 'reg_alpha': 0.1, 'objective': 'binary', 'verbose': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.9737\n",
      "[100]\tvalid_0's auc: 0.973563\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.976509\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.97354\n",
      "[100]\tvalid_0's auc: 0.972971\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.974172\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.972743\n",
      "[100]\tvalid_0's auc: 0.972343\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.975413\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.970445\n",
      "[100]\tvalid_0's auc: 0.97141\n",
      "[150]\tvalid_0's auc: 0.971789\n",
      "[200]\tvalid_0's auc: 0.971743\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.972\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.971779\n",
      "[100]\tvalid_0's auc: 0.971676\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.973637\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.97650881221791, 0.9741717679185455, 0.9754126135102793, 0.971999753690868, 0.9736365888527381], average 0.9743459072380682\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "# get output of first layer models and construct as input for the second layer          \n",
    "rf_classifier = LGBClassifier(boost_type='rf',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "rf_oof_train, rf_oof_test,rf_model_list = rf_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(rf_oof_train.shape, rf_oof_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample_freq': 1, 'boosting_type': 'gbdt', 'nthread': 40, 'subsample': 0.85, 'min_child_samples': 600, 'min_split_gain': 0, 'reg_lambda': 0.1, 'num_leaves': 80, 'max_bin': 255, 'task': 'train', 'min_child_weight': 0.05, 'learning_rate': 0.05, 'scale_pos_weight': 74.42126014102661, 'metric': {'auc'}, 'max_depth': -1, 'colsample_bytree': 0.7, 'subsample_for_bin': 200000, 'use_missing': 'true', 'reg_alpha': 0.1, 'objective': 'binary', 'verbose': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.979619\n",
      "[100]\tvalid_0's auc: 0.982371\n",
      "[150]\tvalid_0's auc: 0.98345\n",
      "[200]\tvalid_0's auc: 0.983959\n",
      "[250]\tvalid_0's auc: 0.984081\n",
      "[300]\tvalid_0's auc: 0.983992\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's auc: 0.984196\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.978223\n",
      "[100]\tvalid_0's auc: 0.980963\n",
      "[150]\tvalid_0's auc: 0.982521\n",
      "[200]\tvalid_0's auc: 0.983093\n",
      "[250]\tvalid_0's auc: 0.983365\n",
      "[300]\tvalid_0's auc: 0.983185\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's auc: 0.983409\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.977717\n",
      "[100]\tvalid_0's auc: 0.980117\n",
      "[150]\tvalid_0's auc: 0.981965\n",
      "[200]\tvalid_0's auc: 0.982237\n",
      "[250]\tvalid_0's auc: 0.982791\n",
      "[300]\tvalid_0's auc: 0.983217\n",
      "[350]\tvalid_0's auc: 0.983106\n",
      "[400]\tvalid_0's auc: 0.983286\n",
      "[450]\tvalid_0's auc: 0.983399\n",
      "[500]\tvalid_0's auc: 0.983296\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's auc: 0.983431\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.978589\n",
      "[100]\tvalid_0's auc: 0.981946\n",
      "[150]\tvalid_0's auc: 0.983911\n",
      "[200]\tvalid_0's auc: 0.984086\n",
      "[250]\tvalid_0's auc: 0.984283\n",
      "[300]\tvalid_0's auc: 0.984082\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.984322\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.978463\n",
      "[100]\tvalid_0's auc: 0.981878\n",
      "[150]\tvalid_0's auc: 0.9836\n",
      "[200]\tvalid_0's auc: 0.983528\n",
      "[250]\tvalid_0's auc: 0.983648\n",
      "[300]\tvalid_0's auc: 0.983806\n",
      "[350]\tvalid_0's auc: 0.983665\n",
      "[400]\tvalid_0's auc: 0.983662\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's auc: 0.983874\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9841957111930324, 0.9834094542336117, 0.9834305610206078, 0.9843217729244546, 0.9838743170338728], average 0.9838463632811159\n",
      "(994731,) (500538,)\n",
      "{'subsample_freq': 1, 'boosting_type': 'dart', 'nthread': 40, 'subsample': 0.85, 'min_child_samples': 600, 'min_split_gain': 0, 'reg_lambda': 0.1, 'num_leaves': 80, 'max_bin': 255, 'task': 'train', 'min_child_weight': 0.05, 'learning_rate': 0.05, 'scale_pos_weight': 74.42126014102661, 'metric': {'auc'}, 'max_depth': -1, 'colsample_bytree': 0.7, 'subsample_for_bin': 200000, 'use_missing': 'true', 'reg_alpha': 0.1, 'objective': 'binary', 'verbose': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.97851\n",
      "[100]\tvalid_0's auc: 0.979168\n",
      "[150]\tvalid_0's auc: 0.979317\n",
      "[200]\tvalid_0's auc: 0.980319\n",
      "[250]\tvalid_0's auc: 0.981291\n",
      "[300]\tvalid_0's auc: 0.982223\n",
      "[350]\tvalid_0's auc: 0.982775\n",
      "[400]\tvalid_0's auc: 0.983779\n",
      "[450]\tvalid_0's auc: 0.984046\n",
      "[500]\tvalid_0's auc: 0.984422\n",
      "[550]\tvalid_0's auc: 0.98461\n",
      "[600]\tvalid_0's auc: 0.98452\n",
      "[650]\tvalid_0's auc: 0.984635\n",
      "[700]\tvalid_0's auc: 0.984686\n",
      "Early stopping, best iteration is:\n",
      "[643]\tvalid_0's auc: 0.984762\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.976551\n",
      "[100]\tvalid_0's auc: 0.977364\n",
      "[150]\tvalid_0's auc: 0.977751\n",
      "[200]\tvalid_0's auc: 0.97922\n",
      "[250]\tvalid_0's auc: 0.980352\n",
      "[300]\tvalid_0's auc: 0.980888\n",
      "[350]\tvalid_0's auc: 0.981173\n",
      "[400]\tvalid_0's auc: 0.981929\n",
      "[450]\tvalid_0's auc: 0.982442\n",
      "[500]\tvalid_0's auc: 0.983136\n",
      "[550]\tvalid_0's auc: 0.983833\n",
      "[600]\tvalid_0's auc: 0.983911\n",
      "[650]\tvalid_0's auc: 0.984366\n",
      "[700]\tvalid_0's auc: 0.984465\n",
      "[750]\tvalid_0's auc: 0.984793\n",
      "[800]\tvalid_0's auc: 0.984776\n",
      "[850]\tvalid_0's auc: 0.984864\n",
      "[900]\tvalid_0's auc: 0.984909\n",
      "[950]\tvalid_0's auc: 0.984995\n",
      "[1000]\tvalid_0's auc: 0.984897\n",
      "[1050]\tvalid_0's auc: 0.985243\n",
      "[1100]\tvalid_0's auc: 0.985346\n",
      "[1150]\tvalid_0's auc: 0.985381\n",
      "Early stopping, best iteration is:\n",
      "[1083]\tvalid_0's auc: 0.985433\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.97571\n",
      "[100]\tvalid_0's auc: 0.977283\n",
      "[150]\tvalid_0's auc: 0.978162\n",
      "[200]\tvalid_0's auc: 0.979183\n",
      "[250]\tvalid_0's auc: 0.980006\n",
      "[300]\tvalid_0's auc: 0.980547\n",
      "[350]\tvalid_0's auc: 0.981255\n",
      "[400]\tvalid_0's auc: 0.982174\n",
      "[450]\tvalid_0's auc: 0.982669\n",
      "[500]\tvalid_0's auc: 0.983348\n",
      "[550]\tvalid_0's auc: 0.983839\n",
      "[600]\tvalid_0's auc: 0.983738\n",
      "[650]\tvalid_0's auc: 0.984016\n",
      "[700]\tvalid_0's auc: 0.984252\n",
      "[750]\tvalid_0's auc: 0.983993\n",
      "[800]\tvalid_0's auc: 0.98377\n",
      "Early stopping, best iteration is:\n",
      "[718]\tvalid_0's auc: 0.984342\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.976992\n",
      "[100]\tvalid_0's auc: 0.978928\n",
      "[150]\tvalid_0's auc: 0.979714\n",
      "[200]\tvalid_0's auc: 0.9811\n",
      "[250]\tvalid_0's auc: 0.98175\n",
      "[300]\tvalid_0's auc: 0.982516\n",
      "[350]\tvalid_0's auc: 0.982741\n",
      "[400]\tvalid_0's auc: 0.983601\n",
      "[450]\tvalid_0's auc: 0.984028\n",
      "[500]\tvalid_0's auc: 0.984665\n",
      "[550]\tvalid_0's auc: 0.985359\n",
      "[600]\tvalid_0's auc: 0.985336\n",
      "[650]\tvalid_0's auc: 0.985397\n",
      "[700]\tvalid_0's auc: 0.985607\n",
      "[750]\tvalid_0's auc: 0.985601\n",
      "[800]\tvalid_0's auc: 0.98558\n",
      "Early stopping, best iteration is:\n",
      "[710]\tvalid_0's auc: 0.985691\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.976808\n",
      "[100]\tvalid_0's auc: 0.978548\n",
      "[150]\tvalid_0's auc: 0.978452\n",
      "[200]\tvalid_0's auc: 0.979166\n",
      "[250]\tvalid_0's auc: 0.980742\n",
      "[300]\tvalid_0's auc: 0.981426\n",
      "[350]\tvalid_0's auc: 0.981502\n",
      "[400]\tvalid_0's auc: 0.982281\n",
      "[450]\tvalid_0's auc: 0.983285\n",
      "[500]\tvalid_0's auc: 0.983531\n",
      "[550]\tvalid_0's auc: 0.983981\n",
      "[600]\tvalid_0's auc: 0.984119\n",
      "[650]\tvalid_0's auc: 0.984222\n",
      "[700]\tvalid_0's auc: 0.984276\n",
      "[750]\tvalid_0's auc: 0.984443\n",
      "[800]\tvalid_0's auc: 0.984549\n",
      "[850]\tvalid_0's auc: 0.984672\n",
      "[900]\tvalid_0's auc: 0.984768\n",
      "[950]\tvalid_0's auc: 0.984819\n",
      "[1000]\tvalid_0's auc: 0.984786\n",
      "[1050]\tvalid_0's auc: 0.984832\n",
      "[1100]\tvalid_0's auc: 0.984911\n",
      "[1150]\tvalid_0's auc: 0.98482\n",
      "Early stopping, best iteration is:\n",
      "[1095]\tvalid_0's auc: 0.984936\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9847623181214559, 0.9854328891044315, 0.9843418471875482, 0.9856911333245589, 0.984936315607722], average 0.9850329006691434\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = LGBClassifier(boost_type='gbdt',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "gbdt_oof_train, gbdt_oof_test,gbdt_model_list = gbdt_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(gbdt_oof_train.shape, gbdt_oof_test.shape)  \n",
    "\n",
    "dart_classifier = LGBClassifier(boost_type='dart',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "dart_oof_train, dart_oof_test,dart_model_list = dart_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(dart_oof_train.shape, dart_oof_test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 18:57:26][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:56<00:00, 11.20s/it]\n",
      "100%|██████████| 5/5 [01:10<00:00, 14.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 18:59:33][Classification: Building Layer-1 Stack] End   ...[Elapsed: 127.34s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 18:59:33][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.51s/it]\n",
      "100%|██████████| 5/5 [00:30<00:00,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 19:00:27][Classification: Building Layer-1 Stack] End   ...[Elapsed: 53.57s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_train = stack_layer1_result_wo_rf(x_train,rf_model_list,gbdt_model_list,dart_model_list)\n",
    "stacked_test = stack_layer1_result_wo_rf(x_test,rf_model_list,gbdt_model_list,dart_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ant-Score: 0.4671388101983003\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xu4VVW9//H3h42AF0QFLAERFLzg\nDZWDUmbeRY9mpUfxmEc9djhWVl7qpx0rL9VjZmWZlpmlWQleKiVTqbzfFfICAiqiCYqKCArKReD7\n+2PM7Vps1l577s1eF/b+vJ5nPXvNOcea8zvWWnt+1xhzzjEVEZiZmTWnS60DMDOz+uZEYWZmZTlR\nmJlZWU4UZmZWlhOFmZmV5URhZmZlOVFYbpKOl/S3WsdRTyQtlrR1DbY7SFJI6lrtbVeCpGcl7duG\n1/k7WQVOFOsoSS9LWpLtqF6XdK2kjSq5zYj4Q0QcXMltFJP0MUl3S1ok6R1Jf5E0rFrbLxHPvZI+\nXzwvIjaKiFkV2t62km6S9FZW/2cknSmpoRLba6ssYQ1Zm3VExI4RcW8L21kjOVb7O9lZOVGs246I\niI2A4cBuwDdqHE+blPpVLGkU8DfgVqAfMBh4GnioEr/g6+2XuaRtgMeA2cDOEdEL+A9gBNCznbdV\ns7rX2/tuzYgIP9bBB/AycGDR9A+AvxZNdwd+CLwCvAFcCaxftPxI4CngXeBFYHQ2vxfwa2Au8Crw\nXaAhW3YS8GD2/BfAD5vEdCtwZva8H/BHYB7wEvCVonLnAzcDv8+2//kS9XsA+HmJ+XcA12XP9wXm\nAP8HvJW9J8fneQ+KXns28DrwO2BT4LYs5gXZ8wFZ+e8BK4GlwGLg8mx+AEOy59cCVwB/BRaRdvTb\nFMVzMPAc8A7wc+C+UnXPyv6++PMssXxQtu0Ts/q9BZxbtHwk8AiwMPssLwe6FS0P4EvAC8BL2byf\nkhLTu8Bk4BNF5Ruy9/nFrG6TgS2B+7N1vZe9L8dm5Q8nfb8WAg8DuzT57p4NPAMsA7pS9H3OYp+U\nxfEG8ONs/ivZthZnj1EUfSezMjsCfwfezl77f7X+X+0Ij5oH4EcbP7jV/7EGAFOAnxYtvxSYAGxG\n+gX6F+CibNnIbGd1EKlV2R/YPlv2Z+CXwIbA5sDjwP9myz78pwT2yXYqyqY3BZaQEkSXbEfybaAb\nsDUwCzgkK3s+8AHw6azs+k3qtgFpp7xfiXqfDMzNnu8LrAB+TEoKn8x2WNvleA8aX3tx9tr1gd7A\nUdn2ewI3AbcUbftemuzYWTNRzM/e367AH4Dx2bI+2Y7vs9myr2bvQXOJ4nXg5DKf/6Bs27/KYt+V\ntNPdIVu+B7BXtq1BwHTg9CZx/z17bxqT5+ey96ArcFYWQ49s2ddJ37HtAGXb6930PcimdwPeBPYk\nJZgTSd/X7kXf3adIiWb9onmN3+dHgBOy5xsBezWpc9eibZ1E4TvZk5QUzwJ6ZNN71vp/tSM8ah6A\nH2384NI/1mLSr7sA7gI2yZaJtMMs/jU7isIvx18Cl5ZY50eynU1xy+M44J7sefE/pUi/8PbJpv8H\nuDt7vifwSpN1fwO4Jnt+PnB/mboNyOq0fYllo4EPsuf7knb2GxYtvxH4Vo73YF9geeOOsJk4hgML\niqbvpeVEcXXRssOAGdnz/wIeKVomUqJtLlF8QNbKa2Z5405zQNG8x4ExzZQ/Hfhzk7j3b+E7tgDY\nNXv+HHBkM+WaJopfAN9pUuY54JNF393/LvF9bkwU9wMXAH2aqXNzieI44MlK/t911of7B9dtn46I\nf0j6JHA96VfrQqAv6VfxZEmNZUX6dQfpl9ztJda3FbAeMLfodV1IO7TVRERIGk/657wf+E9Sd0nj\nevpJWlj0kgZSd1KjNdZZZAGwCtgCmNFk2RakbpYPy0bEe0XT/yK1alp6DwDmRcTSDxdKG5BaIaNJ\nLSSAnpIaImJlmXiLvV70/H3SL2KymD6sc/b+zSmznvmkurZpe5K2JbW0RpDeh66kVl6x1T4DSV8D\nTsliDWBj0ncK0nfmxRzxQPr8T5T05aJ53bL1ltx2E6cAFwIzJL0EXBARt+XYbmtitFbwwewOICLu\nI/2a/WE26y1SN9COEbFJ9ugV6cA3pH/SbUqsajapRdGn6HUbR8SOzWx6HHC0pK1IrYg/Fq3npaJ1\nbBIRPSPisOKwy9TnPVL3w3+UWHwMqfXUaFNJGxZNDwRey/EelIrhLFLXyp4RsTGpew1Sgikbcw5z\nSS2ltMKUvQY0X5x/kLrB2uoXpCQ7NKvL/1GoR6MP6yPpE8D/I72/m0bEJqTuycbXNPedKWU28L0m\nn/8GETGu1LabiogXIuI4UtfnxcDN2Wfc0vs/m9TNae3MiaLj+AlwkKRdI2IVqe/6UkmbA0jqL+mQ\nrOyvgZMlHSCpS7Zs+4iYSzrT6EeSNs6WbZO1WNYQEU+SdshXAxMjorEF8TiwSNLZktaX1CBpJ0n/\n1or6nEP6VfoVST0lbSrpu6TuowualL1AUrdsZ3c4cFOO96CUnqTkslDSZsB5TZa/Qdt3RH8Fdpb0\n6exMny8BHy1T/jzgY5IukfTRLP4hkn4vaZMc2+tJOiayWNL2wBdylF9BOpDfVdK3SS2KRlcD35E0\nVMkuknpny5q+L78CTpW0Z1Z2Q0n/LinX2VqSPiepb/YZNn6nVmWxraL5z+A2YAtJp0vqnn1v9syz\nTSvPiaKDiIh5wHWkA8iQziqZCTwq6V3SL9TtsrKPkw4KX0r61XgfqbsAUl96N2AaqQvoZsp3gVwP\nHJj9bYxlJWmHPZx0xlNjMunVivo8CBxCOvg7l9SltBuwd0S8UFT09SzO10gHj0+NiMbuqmbfg2b8\nhHRg+C3gUeDOJst/SmpBLZB0Wd66ZPV5i9RC+gGpW2kY6cyeZc2Uf5GUFAcBz0p6h9Rim0Q6LtWS\nr5G6AxeRdtw3tFB+Iqm+z5Pe66Ws3j30Y9Lxn7+REtCvSe8VpGNOv5W0UNIxETGJdMzqctJnM5N0\nLCGv0aQ6Lya952MiYklEvE86++yhbFt7Fb8oIhaRTtA4gvS9eAHYrxXbtWY0nrFits7JruT9fUSU\n68KpS5K6kE7PPT4i7ql1PGbluEVhViWSDpG0iaTuFI4ZPFrjsMxaVLFEIek3kt6UNLWZ5cdnQxJM\nkfSwpF0rFYtZnRhFOivnLVL3yKcjYkltQzJrWcW6niTtQzrP/7qI2KnE8o8B0yNigaRDgfMjwgee\nzMzqTMWuo4iI+yUNKrP84aLJRyl/qqCZmdVIvVxwdwppDJ+SJI0FxgJsuOGGe2y//fbVisvMrEOY\nPHnyWxHRty2vrXmikLQfKVHs3VyZiLgKuApgxIgRMWnSpCpFZ2bWMUj6V1tfW9NEIWkX0vn1h0bE\n/FrGYmZmpdXs9FhJA4E/kUaJfL5WcZiZWXkVa1FIGkcaobNPNvjZeaQB54iIK0lXEPcGfp4N2rYi\nIkZUKh4zM2ubSp71dFwLyz8PfL5cGTMzqz1fmW1mZmU5UZiZWVlOFGZmVpYThZmZleVEYWZmZTlR\nmJlZWU4UZmZWlhOFmZmV5URhZmZlOVGYmVlZThRmZlaWE4WZmZXlRGFmZmU5UZiZWVlOFGZmVpYT\nhZmZleVEYWZmZTlRmJlZWU4UZmZWlhOFmZmV5URhZmZlOVGYmVlZThRmZlaWE4WZmZXlRGFmZmVV\nLFFI+o2kNyVNbWa5JF0maaakZyTtXqlYzMys7SrZorgWGF1m+aHA0OwxFvhFBWMxM7M26lqpFUfE\n/ZIGlSlyJHBdRATwqKRNJG0REXMrFZO1vyVL0mPlSlixAhYsgOXL0/O33oJVqyCi8IDVp8vNL543\naxZssklaX9PHBx/A4sVpm43zVq5Mfxctgvffh4aG1m+/eNmbb6Z6bbBB6dc0Ps87r9TyZcvSe1lK\nY7nWLGvLa+plW/Wyvr/+FT7+8eaXdxYVSxQ59AdmF03PyeatkSgkjSW1Ohg4cGBVgusM3nuvsFNf\ntAimT0873Bkz4PnnoWfPNP+dd9KOt/Hx+uvp8f77sHRprWtR0KMHdOmy+qOhIe18+/UDKT2g8Lz4\n0dz8xmVvvAHbbAPdupV+TePzvPOaLu/SJb3nXZpp5zeWa82ytrymXrZVD+v76Eebf01nUstEkVtE\nXAVcBTBixIgy+d8aRaRf9zNnwrvvwqRJ8Oyz8MILMGVK2snnsdVW6Zd8t25pp9vQAH36QK9esNtu\n0LcvbLopdO2ali1blub17AnrrZfi6N073w651PzieZtttmYiaHx07562b2btr5aJ4lVgy6LpAdk8\na6WVK2H2bPje91JL4MknU0uglF694JBD0s6+WzcYOrSwk1+xIjWze/WCQYOa/2VrZp1LLRPFBOA0\nSeOBPYF3fHyivJkz4dFH4bbbUnfKK6/AtGmFvvlGu+2Wmsy77gqbbw7DhsGGG6b5G25Yu/jNbN1U\nsUQhaRywL9BH0hzgPGA9gIi4ErgdOAyYCbwPnFypWNZFc+fC/ffDrbem7pyHHkp95I023TS1BgYN\ngu23h098IiWEww6rWchm1kFV8qyn41pYHsCXKrX9dcmSJXDXXfDqqzBxItx+e0oOxUaNgr33hhNO\ngAMPdMvAzKpnnTiY3RFFwJ13wlVXwS23FOY3NKQza/bfH0aOhE99Kh0MNjOrFSeKKlm6NJ11dPfd\nqUvpjjvSQWiAMWNgjz1g331TN9JGG9U0VDOz1ThRVNCyZXDNNXDeeemCrWLbb59aDeeem87xNzOr\nV04UFfDUU/DHP8KPflS40nbwYBg7FnbYIR1wXm+92sZoZpaXE0U7Wro0dSPdemuaHjoUjj0Wzj7b\n3Ulmtu5yomgnV18Nl12WrnreYovUohg1qtZRmZmtPSeKtbRwIRx5ZDpADXD99XBc2RODzczWLU4U\na2HBAth553T9w4EHptNcfX2DmXU0ThRrYZ990hXUt96arncwM+uIPOxbG910E0ydCkcf7SRhZh2b\nE0UbLF0KX/oSbLkl/O53tY7GzKyy3PXUBqecAvPmwU9+kobqNjPryNyiaKXJk2HcuHRl9Ve/Wuto\nzMwqz4milS68MA3o9+CDtY7EzKw6nChaYcYM+MtfUkvCI7qaWWfhRNEK112Xbg969tm1jsTMrHqc\nKFrh0kthr73SEB1mZp2FE0VO06al02KHDKl1JGZm1eVEkdPEienvWWfVNg4zs2pzoshp8mSQYKed\nah2JmVl1OVHksHIl3HxzGvhPqnU0ZmbV5USRw+TJ6bamvr+EmXVGThQ5PPBA+nvqqbWNw8ysFpwo\ncpg+HTbf3KfFmlnnVNFEIWm0pOckzZR0TonlAyXdI+lJSc9IOqyS8bTVjBlpbCczs84oV6KQ1E1S\nq64gkNQAXAEcCgwDjpM0rEmxbwI3RsRuwBjg563ZRrU89JAThZl1Xi0mCkn/DkwB/p5ND5f05xzr\nHgnMjIhZEbEcGA8c2aRMABtnz3sBr+UNvFoWLkx/N964fDkzs44qT4viQmBPYCFARDwF5Gld9Adm\nF03PyeYVOx/4nKQ5wO3Al0utSNJYSZMkTZo3b16OTbefV15Jf4cOrepmzczqRp5E8UFELGwyL9pp\n+8cB10bEAOAw4HeS1ogpIq6KiBERMaJv377ttOl8Zs1Kf3fbraqbNTOrG3kSxXRJxwBdJA2WdCnw\naI7XvQpsWTQ9IJtX7BTgRoCIeAToAfTJse6qeS3rDBswoLZxmJnVSp5EcRqwB7AK+BOwDMhzb7cn\ngKFZculGOlg9oUmZV4ADACTtQEoU1e1basH8+emv7z9hZp1VnntmHxIRZwMf3oVB0mdJSaNZEbFC\n0mnARKAB+E1EPCvpQmBSREwAzgJ+JekMUnfWSRHRXt1a7eKf/4RNN/W9sc2s88qTKL7Jmknh3BLz\n1hARt5MOUhfP+3bR82nAx3PEUDOrVnl8JzPr3JpNFJIOAUYD/SX9uGjRxqRuqE5h7lzYffdaR2Fm\nVjvlWhRvAlOBpcCzRfMXAWtcZd1RzZ4N/frVOgozs9ppNlFExJPAk5L+EBFLqxhTXVm4EDbZpNZR\nmJnVTp5jFP0lfY80DEePxpkRsW3FoqoT772Xbn+6ww61jsTMrHbynB57LXANINK4TTcCN1QwprrR\neBF4la/xMzOrK3kSxQYRMREgIl6MiG+SEkaH50RhZpav62lZNqzGi5JOJV1d3bOyYdUHJwozs3yJ\n4gxgQ+ArwPdIo7z+dyWDqhdvvZX+9qmrQUXMzKqrxUQREY9lTxcBJwBIajoKbIfkFoWZWQvHKCT9\nm6RPS+qTTe8o6TrgsXKv6yiefhoaGnwvCjPr3JpNFJIuAv4AHA/cKel84B7gaaDDnxoLKUmsXOkh\nPMyscyvX9XQksGtELJG0GekmRDtHxKzqhFZ7b7/tGxaZmZXreloaEUsAIuJt4PnOlCQgHaNYubLW\nUZiZ1Va5FsXWkhpHiBUwuGiaiPhsRSOrA927+/iEmVm5RHFUk+nLKxlIPVq8GLbYotZRmJnVVrlB\nAe+qZiD16L33YPDgWkdhZlZbeYbw6LQWL4YNN6x1FGZmteVEUcZ77zlRmJnlThSSulcykHr0/vtO\nFGZmLSYKSSMlTQFeyKZ3lfSzikdWY6tWpXtRrL9+rSMxM6utPC2Ky4DDgfkAEfE0sF8lg6oHS5ak\nv25RmFlnlydRdImIfzWZ1+EvQ3v//fR3gw1qG4eZWa3lGWZ8tqSRQEhqAL4MPF/ZsGqvMVG468nM\nOrs8LYovAGcCA4E3gL2yeR3asmXpb48e5cuZmXV0eVoUKyJiTMUjqTONiaJ7pzvXy8xsdXlaFE9I\nul3SiZJadQtUSaMlPSdppqRzmilzjKRpkp6VdH1r1l9JjYmiW7faxmFmVmstJoqI2Ab4LrAHMEXS\nLZJabGFkxzOuAA4FhgHHSRrWpMxQ4BvAxyNiR+D01lehMpYvT3/dojCzzi7XBXcR8XBEfAXYHXiX\ndEOjlowEZkbErIhYDown3eOi2P8AV0TEgmw7b+aOvMLc9WRmluS54G4jScdL+gvwODAP+FiOdfcn\n3eyo0ZxsXrFtgW0lPSTpUUmjm4lhrKRJkibNa7yRdYU1tijc9WRmnV2eg9lTgb8AP4iIByqw/aHA\nvsAA4H5JO0fEwuJCEXEVcBXAiBEjop1jKMktCjOzJE+i2DoiVrVh3a8CWxZND8jmFZsDPBYRHwAv\nSXqelDieaMP22pUPZpuZJc0mCkk/ioizgD9KWuNXfI473D0BDJU0mJQgxgD/2aTMLcBxwDWS+pC6\nouridqs+mG1mlpRrUdyQ/W3Tne0iYoWk04CJQAPwm4h4VtKFwKSImJAtO1jSNNKwIF+PiPlt2V57\nc9eTmVlS7g53j2dPd4iI1ZJFlgBavANeRNwO3N5k3reLngfpqu8zWxFzVbjrycwsyXN67H+XmHdK\newdSb9z1ZGaWlDtGcSzpuMJgSX8qWtQTWFj6VR2HWxRmZkm5YxSPk+5BMYB0hXWjRcCTlQyqHrhF\nYWaWlDtG8RLwEvCP6oVTP5Ytgy5doGueE4jNzDqwcl1P90XEJyUtAIpPjxXpOPRmFY+uhpYtc7eT\nmRmU73pqvN1pn2oEUm+WL3e3k5kZlDnrqehq7C2BhohYCYwC/hfo8HeSdovCzCzJc3rsLaTboG4D\nXEMaYqNu7htRKcuWuUVhZgb5EsWqbCymzwI/i4gzWHMU2A7HXU9mZkmeRLFC0n8AJwC3ZfPWq1xI\n9cFdT2ZmSd4rs/cjDTM+Kxvkb1xlw6o9dz2ZmSUtXiUQEVMlfQUYIml70l3rvlf50Gpr+XK3KMzM\nIEeikPQJ4HekocIFfFTSCRHxUKWDqyW3KMzMkjzXHV8KHBYR0wAk7UBKHCMqGVitLV8OG2xQ6yjM\nzGovzzGKbo1JAiAipgMdvlPGB7PNzJI8LYp/SroS+H02fTydYFBAdz2ZmSV5EsWpwFeA/5dNPwD8\nrGIR1QkfzDYzS8omCkk7A9sAf46IH1QnpPrgFoWZWdLsMQpJ/0cavuN44O+SSt3prsNyi8LMLCnX\nojge2CUi3pPUl3Tv699UJ6zac6IwM0vKnfW0LCLeA4iIeS2U7XA++ADW6/ADlZiZtaxci2Lrontl\nC9im+N7ZEfHZikZWYx984BaFmRmUTxRHNZm+vJKB1JslS9yiMDOD8vfMvquagdSTVdktm956q7Zx\nmJnVg4oed5A0WtJzkmZKOqdMuaMkhaS6GBZkxYr0d6utahuHmVk9qFiikNQAXAEcCgwDjpM0rES5\nnsBXgccqFUtrNSaKhobaxmFmVg9yJwpJrb38bCRpSPJZEbEcGA8cWaLcd4CLgaWtXH/FNCaKrnmu\nWzcz6+BaTBSSRkqaAryQTe8qKc8QHv2B2UXTc2hyC1VJuwNbRsRfW4hhrKRJkibNmzcvx6bXzsqV\n6a8ThZlZvhbFZcDhwHyAiHiadMe7tSKpC/Bj4KyWykbEVRExIiJG9O3bd2033SJ3PZmZFeRJFF0i\n4l9N5q3M8bpXgS2Lpgdk8xr1BHYC7pX0MrAXMKEeDmi7RWFmVpAnUcyWNBIISQ2STgeez/G6J4Ch\nkgZL6gaMASY0LoyIdyKiT0QMiohBwKPApyJiUuur0b58jMLMrCBPovgCcCYwEHiD9Mv/Cy29KCJW\nAKcBE4HpwI0R8aykCyV9qu0hV567nszMClr8zRwRb5JaA60WEbeTBhMsnvftZsru25ZtVIK7nszM\nClrcFUr6FRBN50fE2IpEVAfcojAzK8jzm/kfRc97AJ9h9dNeOxy3KMzMCvJ0Pd1QPC3pd8CDFYuo\nDvhgtplZQVuG8BgMfKS9A6kn7noyMyvIc4xiAYVjFF2At4FmB/jrCNz1ZGZWUHZXKEnArhQulFsV\nEWsc2O5o3KIwMyso2/WUJYXbI2Jl9ujwSQJ8jMLMrFieYxRPSdqt4pHUEXc9mZkVNLsrlNQ1u7p6\nN+AJSS8C75Hunx0RsXuVYqw6dz2ZmRWU+838OLA7UNfDbVSCWxRmZgXldoUCiIgXqxRL3fAxCjOz\ngnK7wr6SzmxuYUT8uALx1AV3PZmZFZRLFA3ARmQti87EXU9mZgXldoVzI+LCqkVSR9yiMDMrKHd6\nbKdrSTRyi8LMrKBcojigalHUGR/MNjMraDZRRMTb1QyknrjrycysoC2jx3Z47noyMytwoijBLQoz\nswInihJ8jMLMrMCJogR3PZmZFThRlOCuJzOzAieKEtyiMDMrcKIowccozMwKKpooJI2W9JykmZLW\nuM+2pDMlTZP0jKS7JG1VyXjycteTmVlBxRKFpAbgCuBQYBhwnKRhTYo9CYyIiF2Am4EfVCqe1mjs\neuri9paZWUVbFCOBmRExKyKWA+OBI4sLRMQ9EfF+NvkoMKCC8eS2YkVqTajTjnZlZlZQyUTRH5hd\nND0nm9ecU4A7KhhPbitX+viEmVmjutgdSvocMAL4ZDPLxwJjAQYOHFjxeFascKIwM2tUyRbFq8CW\nRdMDsnmrkXQgcC7wqYhYVmpFEXFVRIyIiBF9+/atSLDFGruezMyssoniCWCopMGSugFjgAnFBSTt\nBvySlCTerGAsreKuJzOzgooliohYAZwGTASmAzdGxLOSLpT0qazYJaTbrd4k6SlJE5pZXVW568nM\nrKCiu8OIuB24vcm8bxc9P7CS228rdz2ZmRX4SoES3PVkZlbgRFHCyy/7Ggozs0ZOFCX06wdz59Y6\nCjOz+uBEUUIEbFUXo06ZmdWeE0UJq1a568nMrJETRQkRHhDQzKyRd4clrFrlRGFm1si7wxLc9WRm\nVuBEUYK7nszMCrw7LMEtCjOzAieKEtyiMDMr8O6wBB/MNjMr8O6wBHc9mZkVOFGU4K4nM7MC7w5L\ncIvCzKzAiaIEtyjMzAq8OyzBB7PNzAq8OyzBXU9mZgVOFCW468nMrMC7wxLcojAzK3CiKMEtCjOz\nAu8OS/DBbDOzgq61DqAeuevJrH188MEHzJkzh6VLl9Y6lE6jR48eDBgwgPXWW6/d1ulEUYK7nsza\nx5w5c+jZsyeDBg1C/vVVcRHB/PnzmTNnDoMHD2639Xp3WIJbFGbtY+nSpfTu3dtJokok0bt373Zv\nwVU0UUgaLek5STMlnVNieXdJN2TLH5M0qJLx5OUWhVn7cZKorkq83xXbHUpqAK4ADgWGAcdJGtak\n2CnAgogYAlwKXFypeFrDB7PNzAoquTscCcyMiFkRsRwYDxzZpMyRwG+z5zcDB6gOfn6468msY7nl\nlluQxIwZMz6cd++993L44YevVu6kk07i5ptvBtKB+HPOOYehQ4ey++67M2rUKO644461juWiiy5i\nyJAhbLfddkycOLFkmbvvvpvdd9+dnXbaiRNPPJEVK1YA8M4773DEEUew6667suOOO3LNNdesdTx5\nVDJR9AdmF03PyeaVLBMRK4B3gN5NVyRprKRJkibNmzevQuEWbLMNDBpU8c2YWZWMGzeOvffem3Hj\nxuV+zbe+9S3mzp3L1KlT+ec//8ktt9zCokWL1iqOadOmMX78eJ599lnuvPNOvvjFL7Jy5crVyqxa\ntYoTTzyR8ePHM3XqVLbaait++9v0e/qKK65g2LBhPP3009x7772cddZZLF++fK1iymOdOOspIq4C\nrgIYMWJEVHp7N9xQ6S2YdT6nnw5PPdW+6xw+HH7yk/JlFi9ezIMPPsg999zDEUccwQUXXNDiet9/\n/31+9atf8dJLL9G9e3cAPvKRj3DMMcesVby33norY8aMoXv37gwePJghQ4bw+OOPM2rUqA/LzJ8/\nn27durHtttsCcNBBB3HRRRdxyimnIIlFixYRESxevJjNNtuMrl0rvxuvZIviVWDLoukB2bySZSR1\nBXoB8ysYk5l1MrfeeiujR49m2223pXfv3kyePLnF18ycOZOBAwey8cYbt1j2jDPOYPjw4Ws8vv/9\n769R9tVXX2XLLQu7xQEDBvDqq6vvFvv06cOKFSuYNGkSADfffDOzZ6fOmdNOO43p06fTr18/dt55\nZ37605/SpQoHVCuZip4AhkoaTEoIY4D/bFJmAnAi8AhwNHB3RFS8xWBm1dfSL/9KGTduHF/96lcB\nGDNmDOPGjWOPPfZo9uyg1h5/H6QvAAAKjElEQVQmvfTSS9c6xqbbHz9+PGeccQbLli3j4IMPpqGh\nAYCJEycyfPhw7r77bl588UUOOuggPvGJT+RKaGujYokiIlZIOg2YCDQAv4mIZyVdCEyKiAnAr4Hf\nSZoJvE1KJmZm7eLtt9/m7rvvZsqUKUhi5cqVSOKSSy6hd+/eLFiwYI3yffr0YciQIbzyyiu8++67\nLe6EzzjjDO6555415o8ZM4Zzzln9qoD+/ft/2DqAdEFi//5ND93CqFGjeOCBBwD429/+xvPPPw/A\nNddcwznnnIMkhgwZwuDBg5kxYwYjR47M94a0VUSsU4899tgjzGzdMG3atJpu/5e//GWMHTt2tXn7\n7LNP3HfffbF06dIYNGjQhzG+/PLLMXDgwFi4cGFERHz961+Pk046KZYtWxYREW+++WbceOONaxXP\n1KlTY5dddomlS5fGrFmzYvDgwbFixYo1yr3xxhsREbF06dLYf//946677oqIiFNPPTXOO++8iIh4\n/fXXo1+/fjFv3rw1Xl/qfSf9QG/TftdXC5hZhzVu3Dg+85nPrDbvqKOOYty4cXTv3p3f//73nHzy\nyQwfPpyjjz6aq6++ml69egHw3e9+l759+zJs2DB22mknDj/88LXu4tlxxx055phjGDZsGKNHj+aK\nK674sFvpsMMO47XXXgPgkksuYYcddmCXXXbhiCOOYP/99wfSmVgPP/wwO++8MwcccAAXX3wxffr0\nWauY8lCsY4cERowYEY0Hecysvk2fPp0ddtih1mF0OqXed0mTI2JEW9bnFoWZmZXlRGFmZmU5UZhZ\nRa1r3dvrukq8304UZlYxPXr0YP78+U4WVRLZ/Sh69OjRrutdJ4bwMLN104ABA5gzZw7VGKPNksY7\n3LUnJwozq5j11luvXe+0ZrXhriczMyvLicLMzMpyojAzs7LWuSuzJc0D/lWFTfUB3qrCdqqhI9UF\nOlZ9OlJdoGPVpyPVBWC7iOjZlheucwezI6JvNbYjaVJbL3evNx2pLtCx6tOR6gIdqz4dqS6Q6tPW\n17rryczMynKiMDOzspwomndVrQNoRx2pLtCx6tOR6gIdqz4dqS6wFvVZ5w5mm5lZdblFYWZmZTlR\nmJlZWZ0+UUgaLek5STMlnVNieXdJN2TLH5M0qPpR5pOjLmdKmibpGUl3SdqqFnHm1VJ9isodJSkk\n1e2pjHnqIumY7PN5VtL11Y6xNXJ81wZKukfSk9n37bBaxJmHpN9IelPS1GaWS9JlWV2fkbR7tWPM\nK0ddjs/qMEXSw5J2zbXitt5suyM8gAbgRWBroBvwNDCsSZkvAldmz8cAN9Q67rWoy37ABtnzL9Rr\nXfLWJyvXE7gfeBQYUeu41+KzGQo8CWyaTW9e67jXsj5XAV/Ing8DXq513GXqsw+wOzC1meWHAXcA\nAvYCHqt1zGtRl48VfccOzVuXzt6iGAnMjIhZEbEcGA8c2aTMkcBvs+c3AwdIUhVjzKvFukTEPRHx\nfjb5KNC+YxG3rzyfDcB3gIuBpdUMrpXy1OV/gCsiYgFARLxZ5RhbI099Atg4e94LeK2K8bVKRNwP\nvF2myJHAdZE8CmwiaYvqRNc6LdUlIh5u/I7Rin1AZ08U/YHZRdNzsnkly0TECuAdoHdVomudPHUp\ndgrpV1K9arE+WRfAlhHx12oG1gZ5PpttgW0lPSTpUUmjqxZd6+Wpz/nA5yTNAW4Hvlyd0Cqitf9b\n64rc+4B1bggPW3uSPgeMAD5Z61jaSlIX4MfASTUOpb10JXU/7Uv6lXe/pJ0jYmFNo2q744BrI+JH\nkkYBv5O0U0SsqnVgBpL2IyWKvfOU7+wtileBLYumB2TzSpaR1JXUjJ5flehaJ09dkHQgcC7wqYhY\nVqXY2qKl+vQEdgLulfQyqe94Qp0e0M7z2cwBJkTEBxHxEvA8KXHUozz1OQW4ESAiHgF6kAbZWxfl\n+t9aV0jaBbgaODIicu3LOnuieAIYKmmwpG6kg9UTmpSZAJyYPT8auDuyI0F1psW6SNoN+CUpSdRz\nHzi0UJ+IeCci+kTEoIgYROpv/VREtHngswrK8z27hdSaQFIfUlfUrGoG2Qp56vMKcACApB1IiWJd\nvR/qBOC/srOf9gLeiYi5tQ6qLSQNBP4EnBARz+d+Ya2P0tf6QTqj4XnSWRznZvMuJO10IH3BbwJm\nAo8DW9c65rWoyz+AN4CnsseEWse8NvVpUvZe6vSsp5yfjUhdadOAKcCYWse8lvUZBjxEOiPqKeDg\nWsdcpi7jgLnAB6SW3SnAqcCpRZ/NFVldp9T596ylulwNLCjaB0zKs14P4WFmZmV19q4nMzNrgROF\nmZmV5URhZmZlOVGYmVlZThRmZlaWE4XVHUkrJT1V9BhUpuyg5kbKbOU2781GQ306G0Zjuzas41RJ\n/5U9P0lSv6JlV0sa1s5xPiFpeI7XnC5pg7XdtnVeThRWj5ZExPCix8tV2u7xEbEraRDIS1r74oi4\nMiKuyyZPAvoVLft8RExrlygLcf6cfHGeDjhRWJs5Udg6IWs5PCDpn9njYyXK7Cjp8awV8oykodn8\nzxXN/6WkhhY2dz8wJHvtAdk9FaZkY/13z+Z/X4V7e/wwm3e+pK9JOpo0ltYfsm2un7UERmStjg93\n7lnL4/I2xvkIRYPTSfqFpElK97O4IJv3FVLCukfSPdm8gyU9kr2PN0naqIXtWCfnRGH1aP2ibqc/\nZ/PeBA6KiN2BY4HLSrzuVOCnETGctKOekw0fcSzw8Wz+SuD4FrZ/BDBFUg/gWuDYiNiZNHDfFyT1\nBj4D7BgRuwDfLX5xRNwMTCL98h8eEUuKFv8xe22jY4HxbYxzNGnoj0bnRsQIYBfgk5J2iYjLSEN8\n7xcR+2XDg3wTODB7LycBZ7awHevkPHqs1aMl2c6y2HrA5Vmf/ErSWEhNPQKcK2kA8KeIeEHSAcAe\nwBNKtxFZn5R0SvmDpCXAy6RhsbcDXorCmDi/Bb4EXE66/8WvJd0G3Ja3YhExT9KsbMygF4DtSUNd\nfKmVcXYDNgKK36djJI0l/V9vQRpG45kmr90rm/9Qtp1upPfNrFlOFLauOIM0TtWupJbwGjcqiojr\nJT0G/Dtwu6T/JY3T89uI+EaObRwfRYMKStqsVKGIWCFpJGnQu6OB04D9W1GX8cAxwAzgzxERSnvt\n3HECk0nHJ34GfFbSYOBrwL9FxAJJ15LGKWtKwN8j4rhWxGudnLuebF3RC5gb6X4GJ5Bux7kaSVsD\ns7LulltJXTB3AUdL2jwrs5ny3yv8OWCQpCHZ9AnAfVmffq+IuJ2UwErdd3gRaSj0Uv5MumvacaSk\nQWvjjDRI27eAvSRtT7qb3HvAO5I+QrrNZalYHgU+3lgnSRtKKtU6M/uQE4WtK34OnCjpaVJ3zXsl\nyhwDTJX0FOleFddlZxp9E/ibpGeAv5O6ZVoUEUuBk4GbJE0BVgFXkna6t2Xre5DSffzXAlc2Hsxu\nst4FwHRgq4h4PJvX6jizYx8/Ar4eEU+T7rk9A7ie1J3V6CrgTkn3RMQ80hlZ47LtPEJ6P82a5dFj\nzcysLLcozMysLCcKMzMry4nCzMzKcqIwM7OynCjMzKwsJwozMyvLicLMzMr6/9pewvz8mq1tAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use XGBOOST  as the model of the second layer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = pd.DataFrame(model.predict_proba(x_val))[1]\n",
    "\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "final_model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=1,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,    \n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict_proba(stacked_test)\n",
    "\n",
    "result=pd.DataFrame()\n",
    "result['id'] = val_df['id']\n",
    "result['score'] = pd.DataFrame(test_prediction)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./submit_2018_07_03_1800.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7ed0b865c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[result.score > 0.001]['score'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>661ae9a03c6c74feab2555c9987e140ae3f5421bd8e7a0...</td>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ada98d4358e72a27cc5e92f691a87a4fd62a7cda0387e2...</td>\n",
       "      <td>0.000556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e33675a962e5bf44d05a2b01903a4beb88a0c6385c05c6...</td>\n",
       "      <td>0.006990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4c5da176de7172dbd1ad0aa7edf9866548ec720d6c7318...</td>\n",
       "      <td>0.010748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fa39e3491900d49b862d30b5dbcd0b1c30bb4ff0d96396...</td>\n",
       "      <td>0.036123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ae0f1ecb27e098bbf672529a50237dff27abd16b349569...</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7a9e5e415412a92928f91608c39750e3a33eb123eb0ef8...</td>\n",
       "      <td>0.000323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51fb55256e959c36989151e8136a8a68002bb75887eb75...</td>\n",
       "      <td>0.029097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aa7664463d11ae5573ae6d89195373fbe033c354710142...</td>\n",
       "      <td>0.042136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b794af5790f98806ff8ad8ee268caa606dffcfbcb753bd...</td>\n",
       "      <td>0.003241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a099f47a588fe5b366078af171f3b3f8a0fd30baaa5d59...</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6ed1bc5e31141a92144a45c7c1e11354102d42c5defc47...</td>\n",
       "      <td>0.014744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>f2115806fb4e7bb02040f2ffe2c161257d6a39fc221ce5...</td>\n",
       "      <td>0.162220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8559fa3b1229235529d928665c249eef8f54fc3955df8d...</td>\n",
       "      <td>0.002886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e4ff5187b4b03062cb08df59c78d3fc8055e96c7ffb202...</td>\n",
       "      <td>0.038021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>725649121b0c7a037dec608534f2c09239749660d05ba3...</td>\n",
       "      <td>0.105497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6c4da5d009203463fc24d625b6f51b8f955603ddcefadd...</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5b93f6f969faca0da2c2e994120e282555213d4b7f243d...</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7ef528867f0b786f8ddf716005a1b89476ba8014e985e4...</td>\n",
       "      <td>0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38016c269ee3c30ba4a746690c10e320465b43b1d8fa34...</td>\n",
       "      <td>0.008074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>efe457b707d0a2323f14b912a0b7df0da92acd3ecab8f0...</td>\n",
       "      <td>0.249497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>109b580491948ccd625a917bf739eab26c16d3d2d294de...</td>\n",
       "      <td>0.059367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>182a978f6f3d10dfd33fdc50018189bcc69d5092fd5ad3...</td>\n",
       "      <td>0.113779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>e57d5993a958986970643776b1fa275653091dc086fae5...</td>\n",
       "      <td>0.055413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ad1f6fc5830d878522a2b5954ce895e75f608e5ebbcda0...</td>\n",
       "      <td>0.006794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3ac2672974d777e34f250f088449a78b9899f9bca47e9f...</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>d6beea292a72137071d718544571e14c99be666bc15939...</td>\n",
       "      <td>0.121612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>d6c5be3ad2911c6c2667abd178f2b48cc67b816f6c73c0...</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20c5dec89550c5d2cd67bc8c9e456cf72f2ade0cd4e094...</td>\n",
       "      <td>0.005690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83220e10ae92984b40cbdde43563255ba4dc1d378fcd9f...</td>\n",
       "      <td>0.039353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500508</th>\n",
       "      <td>f43709dc4d557dc6bc1c58baa0c69a410cef29cb9e5421...</td>\n",
       "      <td>0.040421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500509</th>\n",
       "      <td>fe488b822d5dab993f3b2a0981d6d861ef72a55cc73e86...</td>\n",
       "      <td>0.000296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500510</th>\n",
       "      <td>b7b603dcfb8103ddc5a433622490a82a0886bc376e7712...</td>\n",
       "      <td>0.136296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500511</th>\n",
       "      <td>ae1aa9517fb8d5739a1a21597eecb3f46981893ae4f1ce...</td>\n",
       "      <td>0.022836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500512</th>\n",
       "      <td>e82aa8f00d5c1446f335b0fbc16fa25a27d1ea67a98f70...</td>\n",
       "      <td>0.026945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500513</th>\n",
       "      <td>7da3923f63a3d4498130db5d768a5b95b109175e7b900d...</td>\n",
       "      <td>0.028004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500514</th>\n",
       "      <td>2321f1bfab231e655db92bdd1e5b46f072fdf9868ae511...</td>\n",
       "      <td>0.000271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500515</th>\n",
       "      <td>d367e64b458cc49f967f567e759bc2d4869eecbb0a886b...</td>\n",
       "      <td>0.094048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500516</th>\n",
       "      <td>f09d99a00a324d705f84481fb2a4d3a88ac213f6e6956c...</td>\n",
       "      <td>0.086081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500517</th>\n",
       "      <td>2752dee973dded20471a7101eced91d2e163b2f342c2ba...</td>\n",
       "      <td>0.000251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500518</th>\n",
       "      <td>ca2ef40a0cb3026132db47a60001f4cc7412022408b0a5...</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500519</th>\n",
       "      <td>c6a4e0c7bd24939c5d7736705e0dd5f26680706cf674d0...</td>\n",
       "      <td>0.013586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500520</th>\n",
       "      <td>940a4907b4a52a85c9b65616ee5013251e981b549e549e...</td>\n",
       "      <td>0.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500521</th>\n",
       "      <td>93a6a8b8d5945f09fdd86b480a423efb9377ca56b0d84f...</td>\n",
       "      <td>0.004978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500522</th>\n",
       "      <td>461a754e89e1b57994516b7a78eb3e16ba3d381996d963...</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500523</th>\n",
       "      <td>80cae5da92f6bc231f33d5259fea649cf63818126e26fb...</td>\n",
       "      <td>0.061757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500524</th>\n",
       "      <td>b672834ee5bc06bb988911d25eddef8da89bdea19395a8...</td>\n",
       "      <td>0.035043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500525</th>\n",
       "      <td>0ebe2cc3856c7f99d51308cd26387baf21034422cb10b1...</td>\n",
       "      <td>0.012567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500526</th>\n",
       "      <td>c51735fbe88fc6b17139f106a7c95473915ab02df98b27...</td>\n",
       "      <td>0.014366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500527</th>\n",
       "      <td>a33ec1f35c2eeff1578b8f17752cfdb06a435c6196e354...</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500528</th>\n",
       "      <td>1966874b1d5fd57c12b0af9c29f4ae56a68d92a38c1c35...</td>\n",
       "      <td>0.050492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500529</th>\n",
       "      <td>d9c3696eb9908a4932640ac110e10bbc408ae2fc8a9fb7...</td>\n",
       "      <td>0.136858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500530</th>\n",
       "      <td>34b259782e71d6f9ed185cb2f2247aab7226c540ad4804...</td>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500531</th>\n",
       "      <td>707faf3b8e50e457c6a0bde48124dcece647f9958b1e3b...</td>\n",
       "      <td>0.006679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500532</th>\n",
       "      <td>3cc349b8263ddcc1760a92645531a081dad0322802dad1...</td>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500533</th>\n",
       "      <td>0439df1d1f280a302ff6afab4aadfba968867f9f201e3a...</td>\n",
       "      <td>0.149866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500534</th>\n",
       "      <td>3a3ad5a2f9fd25be7a8d94b5f70b775b2b43fe95ea6b83...</td>\n",
       "      <td>0.022982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500535</th>\n",
       "      <td>6c827ab84962f224f19ff982c1258ec7b43c66af1a26b1...</td>\n",
       "      <td>0.066419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500536</th>\n",
       "      <td>823b69d54e0a462753af95331529c1e057d9677c217fa1...</td>\n",
       "      <td>0.436096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500537</th>\n",
       "      <td>f3e5ab004160667a7f3c90d801ab460c1ea3d5632bf581...</td>\n",
       "      <td>0.083629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       id     score\n",
       "0       661ae9a03c6c74feab2555c9987e140ae3f5421bd8e7a0...  0.000680\n",
       "1       ada98d4358e72a27cc5e92f691a87a4fd62a7cda0387e2...  0.000556\n",
       "2       e33675a962e5bf44d05a2b01903a4beb88a0c6385c05c6...  0.006990\n",
       "3       4c5da176de7172dbd1ad0aa7edf9866548ec720d6c7318...  0.010748\n",
       "4       fa39e3491900d49b862d30b5dbcd0b1c30bb4ff0d96396...  0.036123\n",
       "5       ae0f1ecb27e098bbf672529a50237dff27abd16b349569...  0.000251\n",
       "6       7a9e5e415412a92928f91608c39750e3a33eb123eb0ef8...  0.000323\n",
       "7       51fb55256e959c36989151e8136a8a68002bb75887eb75...  0.029097\n",
       "8       aa7664463d11ae5573ae6d89195373fbe033c354710142...  0.042136\n",
       "9       b794af5790f98806ff8ad8ee268caa606dffcfbcb753bd...  0.003241\n",
       "10      a099f47a588fe5b366078af171f3b3f8a0fd30baaa5d59...  0.004052\n",
       "11      6ed1bc5e31141a92144a45c7c1e11354102d42c5defc47...  0.014744\n",
       "12      f2115806fb4e7bb02040f2ffe2c161257d6a39fc221ce5...  0.162220\n",
       "13      8559fa3b1229235529d928665c249eef8f54fc3955df8d...  0.002886\n",
       "14      e4ff5187b4b03062cb08df59c78d3fc8055e96c7ffb202...  0.038021\n",
       "15      725649121b0c7a037dec608534f2c09239749660d05ba3...  0.105497\n",
       "16      6c4da5d009203463fc24d625b6f51b8f955603ddcefadd...  0.006625\n",
       "17      5b93f6f969faca0da2c2e994120e282555213d4b7f243d...  0.000216\n",
       "18      7ef528867f0b786f8ddf716005a1b89476ba8014e985e4...  0.002629\n",
       "19      38016c269ee3c30ba4a746690c10e320465b43b1d8fa34...  0.008074\n",
       "20      efe457b707d0a2323f14b912a0b7df0da92acd3ecab8f0...  0.249497\n",
       "21      109b580491948ccd625a917bf739eab26c16d3d2d294de...  0.059367\n",
       "22      182a978f6f3d10dfd33fdc50018189bcc69d5092fd5ad3...  0.113779\n",
       "23      e57d5993a958986970643776b1fa275653091dc086fae5...  0.055413\n",
       "24      ad1f6fc5830d878522a2b5954ce895e75f608e5ebbcda0...  0.006794\n",
       "25      3ac2672974d777e34f250f088449a78b9899f9bca47e9f...  0.000428\n",
       "26      d6beea292a72137071d718544571e14c99be666bc15939...  0.121612\n",
       "27      d6c5be3ad2911c6c2667abd178f2b48cc67b816f6c73c0...  0.000379\n",
       "28      20c5dec89550c5d2cd67bc8c9e456cf72f2ade0cd4e094...  0.005690\n",
       "29      83220e10ae92984b40cbdde43563255ba4dc1d378fcd9f...  0.039353\n",
       "...                                                   ...       ...\n",
       "500508  f43709dc4d557dc6bc1c58baa0c69a410cef29cb9e5421...  0.040421\n",
       "500509  fe488b822d5dab993f3b2a0981d6d861ef72a55cc73e86...  0.000296\n",
       "500510  b7b603dcfb8103ddc5a433622490a82a0886bc376e7712...  0.136296\n",
       "500511  ae1aa9517fb8d5739a1a21597eecb3f46981893ae4f1ce...  0.022836\n",
       "500512  e82aa8f00d5c1446f335b0fbc16fa25a27d1ea67a98f70...  0.026945\n",
       "500513  7da3923f63a3d4498130db5d768a5b95b109175e7b900d...  0.028004\n",
       "500514  2321f1bfab231e655db92bdd1e5b46f072fdf9868ae511...  0.000271\n",
       "500515  d367e64b458cc49f967f567e759bc2d4869eecbb0a886b...  0.094048\n",
       "500516  f09d99a00a324d705f84481fb2a4d3a88ac213f6e6956c...  0.086081\n",
       "500517  2752dee973dded20471a7101eced91d2e163b2f342c2ba...  0.000251\n",
       "500518  ca2ef40a0cb3026132db47a60001f4cc7412022408b0a5...  0.005003\n",
       "500519  c6a4e0c7bd24939c5d7736705e0dd5f26680706cf674d0...  0.013586\n",
       "500520  940a4907b4a52a85c9b65616ee5013251e981b549e549e...  0.002016\n",
       "500521  93a6a8b8d5945f09fdd86b480a423efb9377ca56b0d84f...  0.004978\n",
       "500522  461a754e89e1b57994516b7a78eb3e16ba3d381996d963...  0.000214\n",
       "500523  80cae5da92f6bc231f33d5259fea649cf63818126e26fb...  0.061757\n",
       "500524  b672834ee5bc06bb988911d25eddef8da89bdea19395a8...  0.035043\n",
       "500525  0ebe2cc3856c7f99d51308cd26387baf21034422cb10b1...  0.012567\n",
       "500526  c51735fbe88fc6b17139f106a7c95473915ab02df98b27...  0.014366\n",
       "500527  a33ec1f35c2eeff1578b8f17752cfdb06a435c6196e354...  0.000208\n",
       "500528  1966874b1d5fd57c12b0af9c29f4ae56a68d92a38c1c35...  0.050492\n",
       "500529  d9c3696eb9908a4932640ac110e10bbc408ae2fc8a9fb7...  0.136858\n",
       "500530  34b259782e71d6f9ed185cb2f2247aab7226c540ad4804...  0.000356\n",
       "500531  707faf3b8e50e457c6a0bde48124dcece647f9958b1e3b...  0.006679\n",
       "500532  3cc349b8263ddcc1760a92645531a081dad0322802dad1...  0.001330\n",
       "500533  0439df1d1f280a302ff6afab4aadfba968867f9f201e3a...  0.149866\n",
       "500534  3a3ad5a2f9fd25be7a8d94b5f70b775b2b43fe95ea6b83...  0.022982\n",
       "500535  6c827ab84962f224f19ff982c1258ec7b43c66af1a26b1...  0.066419\n",
       "500536  823b69d54e0a462753af95331529c1e057d9677c217fa1...  0.436096\n",
       "500537  f3e5ab004160667a7f3c90d801ab460c1ea3d5632bf581...  0.083629\n",
       "\n",
       "[500538 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
