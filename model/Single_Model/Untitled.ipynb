{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import atecml.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric o validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        model_list = []\n",
    "        \n",
    "        for i in range(0,n_folds):\n",
    "            \n",
    "            val_index = DateFold[5] #始终用最后20%验证            \n",
    "            train_index = list(all_list - DateFold[i])\n",
    "                            \n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            \n",
    "            #Over_sample\n",
    "            #X_resampled, y_resampled = SMOTE().fit_sample(x_tra,y_tra)\n",
    "            #model, auc = self.train(X_resampled, y_resampled, x_val, y_val)\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            model_list.append(model)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test,model_list\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    '''\n",
    "    ' 调参范围\n",
    "    'num_leaves':range(35,65,5)\n",
    "    'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7]\n",
    "    'min_child_weight':range(1,6,2)\n",
    "    'max_depth':range(3,10,2),\n",
    "    'subsample':[i/10.0 for i in range(6,10)],正常直接设置为1\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]，正常直接设置为1\n",
    "    'reg_alpha','reg_lambda':[1e-5, 1e-2, 0.1, 1, 2,2.5,3]\n",
    "    '''\n",
    "    def __init__(self,boost_type,boost_round=1000,early_stop=100,pos_weight=1):\n",
    "        self.num_boost_round = boost_round\n",
    "        self.early_stopping_rounds = early_stop\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': boost_type,\n",
    "            'max_depth': 3,\n",
    "            'metric': {'auc'},\n",
    "            'nthread': 40,\n",
    "            'num_leaves': 10,\n",
    "            'objective': 'binary',\n",
    "            'verbose' : -1,\n",
    "            #'device': 'gpu'\n",
    "            }\n",
    "        print(self.params)\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets=lgbval, \n",
    "                          verbose_eval = 50,\n",
    "                          num_boost_round = self.num_boost_round,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集为第一步build的纬度提升矩阵，并过滤掉unknown标签\n",
    "train_df = pd.read_pickle('./01_train.dat')\n",
    "val_df =  pd.read_pickle('./01_test.dat')\n",
    "\n",
    "#train_df = atecml.data.load_train()\n",
    "#val_df = atecml.data.load_test()\n",
    "train_df.loc[train_df.label == 0, 'Fraud'] = 0\n",
    "train_df.loc[train_df.label != 0, 'Fraud'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634284, 360447)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "predictors =joblib.load('./woe_feature.dat')\n",
    "#predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_SUM]\n",
    "\n",
    "\n",
    "target = 'Fraud'\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-12').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-13',end_date='2017-09-20').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-21',end_date='2017-09-28').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-09-29',end_date='2017-10-06').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-07',end_date='2017-10-14').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-15',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994731, 168) (994731,) (500538, 168)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array(train_df[predictors])\n",
    "y_train = np.array(train_df[target])\n",
    "x_test = np.array(val_df[predictors])\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16847.0 977884.0 58.04499317385885\n"
     ]
    }
   ],
   "source": [
    "num_pos = np.sum(train_df[target])  \n",
    "num_neg = x_train.shape[0]- num_pos\n",
    "scale_pos_weight =  num_neg/num_pos\n",
    "print(num_pos,num_neg,scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 2000\n",
    "num_early_stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_samples': 20, 'metric': {'auc'}, 'num_leaves': 80, 'subsample': 0.85, 'task': 'train', 'nthread': 40, 'is_unbalance': True, 'learning_rate': 0.05, 'objective': 'binary', 'subsample_freq': 1, 'subsample_for_bin': 2000, 'boosting_type': 'dart', 'verbose': -1, 'use_missing': 'true', 'min_split_gain': 0, 'max_bin': 511, 'colsample_bytree': 0.7, 'max_depth': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.967054\n",
      "[100]\tvalid_0's auc: 0.97075\n",
      "[150]\tvalid_0's auc: 0.973024\n",
      "[200]\tvalid_0's auc: 0.974198\n",
      "[250]\tvalid_0's auc: 0.975055\n",
      "[300]\tvalid_0's auc: 0.975691\n",
      "[350]\tvalid_0's auc: 0.976046\n",
      "[400]\tvalid_0's auc: 0.976443\n",
      "[450]\tvalid_0's auc: 0.97675\n",
      "[500]\tvalid_0's auc: 0.976812\n",
      "[550]\tvalid_0's auc: 0.976832\n",
      "[600]\tvalid_0's auc: 0.977054\n",
      "[650]\tvalid_0's auc: 0.977077\n",
      "[700]\tvalid_0's auc: 0.977027\n",
      "[750]\tvalid_0's auc: 0.976731\n",
      "Early stopping, best iteration is:\n",
      "[690]\tvalid_0's auc: 0.977111\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.969522\n",
      "[100]\tvalid_0's auc: 0.971911\n",
      "[150]\tvalid_0's auc: 0.973478\n",
      "[200]\tvalid_0's auc: 0.97438\n",
      "[250]\tvalid_0's auc: 0.974841\n",
      "[300]\tvalid_0's auc: 0.975543\n",
      "[350]\tvalid_0's auc: 0.975635\n",
      "[400]\tvalid_0's auc: 0.976018\n",
      "[450]\tvalid_0's auc: 0.976209\n",
      "[500]\tvalid_0's auc: 0.97627\n",
      "[550]\tvalid_0's auc: 0.976312\n",
      "[600]\tvalid_0's auc: 0.976047\n",
      "[650]\tvalid_0's auc: 0.976172\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid_0's auc: 0.97635\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.97104\n",
      "[100]\tvalid_0's auc: 0.973092\n",
      "[150]\tvalid_0's auc: 0.974204\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-75c97586ae3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdart_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboost_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dart'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_early_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mscale_pos_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdart_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdart_oof_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdart_model_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdart_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdart_oof_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdart_oof_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-dcd864801905>\u001b[0m in \u001b[0;36mget_oof\u001b[0;34m(self, x_train, y_train, x_test, n_folds)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m#X_resampled, y_resampled = SMOTE().fit_sample(x_tra,y_tra)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#model, auc = self.train(X_resampled, y_resampled, x_val, y_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0maucs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-dcd864801905>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train, x_val, y_val)\u001b[0m\n\u001b[1;32m    103\u001b[0m                           \u001b[0mverbose_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                           early_stopping_rounds = self.early_stopping_rounds)\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "dart_classifier = LGBClassifier(boost_type='dart',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "dart_oof_train, dart_oof_test,dart_model_list = dart_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(dart_oof_train.shape, dart_oof_test.shape)   \n",
    "\n",
    "\n",
    "gbdt_classifier = LGBClassifier(boost_type='gbdt',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "gbdt_oof_train, gbdt_oof_test,gbdt_model_list = gbdt_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(gbdt_oof_train.shape, gbdt_oof_test.shape)  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dart_r = gbdt_oof_train\n",
    "n = int(gbdt_oof_train.shape[0] * 0.8)\n",
    "y_pred, y_val = train_dart_r[n:], y_train[n:]\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dart_r = dart_oof_train\n",
    "n = int(dart_oof_train.shape[0] * 0.8)\n",
    "y_pred, y_val = train_dart_r[n:], y_train[n:]\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
