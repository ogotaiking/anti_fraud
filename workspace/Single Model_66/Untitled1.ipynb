{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import atecml.data\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#build Models...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import random\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_modelfit_nocv(params, dtrain, dvalid, predictors, target='target', objective='binary', metrics='binary_error', model_type='gbdt',\n",
    "                 feval=None, early_stopping_rounds=20, num_boost_round=3000, verbose_eval=50, categorical_features=None):\n",
    "    \n",
    "    lgb_params = {\n",
    "        'boosting_type': model_type,\n",
    "        'objective': objective,\n",
    "        'metric': metrics,\n",
    "        'use_missing' : 'true',\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 64,  # we should let it be smaller than 2^(max_depth)\n",
    "        'max_depth': -1,  # -1 means no limit\n",
    "        #'min_child_samples': 600,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "        'max_bin': 511,  # Number of bucketed bin for feature values\n",
    "        #'colsample_bytree': 0.9,\n",
    "        #'subsample': 0.85,  # Subsample ratio of the training instance.\n",
    "        #'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "        #'min_child_weight': 0.05,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "        #'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "        #'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "        #'reg_alpha': 0.01,  # L1 regularization term on weights\n",
    "        #'reg_lambda': 0.1,  # L2 regularization term on weights\n",
    "        'nthread': 40,\n",
    "        'verbose': -1,\n",
    "    }\n",
    "\n",
    "    lgb_params.update(params)\n",
    "    print(\"preparing validation datasets\")\n",
    "\n",
    "    xgtrain = lgb.Dataset(dtrain[predictors].values, label=dtrain[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "    xgvalid = lgb.Dataset(dvalid[predictors].values, label=dvalid[target].values,\n",
    "                          feature_name=predictors,\n",
    "                          categorical_feature=categorical_features\n",
    "                          )\n",
    "\n",
    "    evals_results = {}\n",
    "\n",
    "    bst1 = lgb.train(lgb_params, \n",
    "                     xgtrain, \n",
    "                     valid_sets=[xgtrain, xgvalid], \n",
    "                     valid_names=['train','valid'], \n",
    "                     evals_result=evals_results, \n",
    "                     num_boost_round=num_boost_round,\n",
    "                     early_stopping_rounds=early_stopping_rounds,\n",
    "                     verbose_eval=verbose_eval, \n",
    "                     feval=feval)\n",
    "\n",
    "    return bst1\n",
    "\n",
    "def model_validation(train_df,val_df,predictors,target,params):\n",
    "    categorical=[]\n",
    "    for item in predictors:\n",
    "        if (item in atecml.data.CATE_FEATURE_LIST):\n",
    "            categorical.append(item)\n",
    "            \n",
    "    if (target == 'Normal'):\n",
    "        params = {\n",
    "            'scale_pos_weight' : 0.01,\n",
    "        } \n",
    "    else:\n",
    "        params = {\n",
    "            'scale_pos_weight' : 60,\n",
    "        }\n",
    "    bst = lgb_modelfit_nocv(params, \n",
    "                        train_df, \n",
    "                        val_df, \n",
    "                        predictors, \n",
    "                        target, \n",
    "                        model_type='dart',\n",
    "                        objective='binary', \n",
    "                        #metrics ='binary',\n",
    "                        metrics={'auc'},\n",
    "                        early_stopping_rounds=100, \n",
    "                        verbose_eval=50, \n",
    "                        num_boost_round=1000, \n",
    "                        categorical_features=categorical\n",
    "                        )\n",
    "    y_predict = bst.predict(val_df[predictors])\n",
    "    if (target == 'Normal'):\n",
    "        y_predict = 1 - y_predict\n",
    "    atec_Score,b,c=atecml.data.accuracy_validation(val_df['Fraud'],y_predict)\n",
    "    return bst,atec_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634284, 360447)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle('./01_train.dat')\n",
    "\n",
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "#predictors = ['mean', 'n_f7', 'f7', 'f15', 'f238', 'f253', 'f210', 'f248', 'f243', 'f247', 'f18', 'n_f6', 'f218', 'f5', 'f234', 'f19', 'f82', 'f4', 'f99', 'f237', 'f215', 'f246', 'n_NaN_LIST', 'f81', 'f84', 'f209', 'f101', 'f85', 'f106', 'f245', 'f17', 'f217', 'f31', 'f216', 'f244', 'f86', 'f242', 'f235', 'f233', 'f58', 'n_f29', 'f204', 'f236', 'f6', 'f8', 'n_f244', 'f250', 'f105', 'f11', 'f53', 'n_f28', 'n_f236', 'f241', 'n_f245', 'f14', 'f226', 'n_f238', 'n_f215', 'f232', 'f223', 'f83', 'f30', 'f266', 'n_f284', 'f214', 'f207', 'f100', 'f252', 'f239', 'f9', 'f231', 'f164', 'n_f235', 'f262', 'f27', 'f208', 'f10', 'f229', 'f55', 'f161', 'n_f30', 'f263', 'f230', 'f12', 'f222', 'f52', 'n_f14', 'f249', 'f219', 'f163', 'n_f294', 'n_f25', 'f240', 'f110', 'f16', 'n_f237', 'n_f17', 'f98', 'f63', 'n_f31', 'f104', 'n_f21', 'f211', 'f3', 'f178', 'f80', 'n_f210', 'n_f208', 'f224', 'f56', 'f213', 'n_f26', 'f251', 'n_f216', 'f57', 'f13', 'f284', 'f103', 'f206', 'f227', 'n_f105', 'f34', 'f291', 'n_f287', 'f212', 'f225', 'n_f24', 'n_f52', 'f185', 'f205', 'n_f286', 'f285', 'f221', 'f286', 'f54', 'f26', 'n_f262', 'f162', 'n_f33', 'f35', 'f278', 'n_f279', 'f73', 'n_f20', 'n_f293', 'f271', 'n_f234', 'f287', 'f79', 'f290', 'f33', 'f102', 'f1', 'n_f285', 'n_f106', 'f264', 'n_f289', 'f220', 'f265', 'n_f49', 'f184', 'f32', 'f75', 'f228', 'n_f95', 'n_f90', 'f50', 'f134', 'f270', 'f165', 'f296', 'f2', 'n_f266', 'f294', 'f283', 'n_f182', 'n_f50', 'n_f291', 'n_f209', 'f259', 'n_f175', 'f78', 'n_f5', 'n_f290', 'f61', 'f123', 'f183', 'f65', 'n_f53', 'f289', 'n_f34', 'n_f295', 'f297', 'n_f51', 'f62', 'f49', 'f21', 'f130', 'f48', 'n_f32']\n",
    "#predictors = ['mean', 'n_f7', 'f7', 'f210', 'f238', 'f15', 'f253', 'f5', 'f99', 'f243', 'f82', 'f248', 'f247', 'f84', 'f234', 'f209', 'f106', 'n_NaN_LIST', 'f18', 'f218', 'n_f6', 'f101', 'f85', 'f204', 'f237', 'f81', 'f19', 'f86', 'f31', 'f215', 'f246', 'n_f28', 'f58', 'n_f284', 'f207', 'f53', 'n_f29', 'f178', 'f266', 'f244', 'f216', 'f4', 'f245', 'f55', 'f242', 'n_f244', 'f217', 'f235', 'f105', 'f9', 'f83', 'f233', 'n_f236', 'f262', 'n_f215', 'f17', 'n_f208', 'f236', 'f100', 'f214', 'f98', 'f30', 'n_f238', 'f208', 'n_f245', 'f6', 'f63', 'n_f25', 'f8', 'f263', 'f110', 'f130', 'f250', 'n_f235', 'f11', 'n_f210', 'n_f21', 'f14', 'n_f294', 'f291', 'f241', 'f226', 'f104', 'f10', 'f185', 'f231', 'n_f105', 'f52', 'f284', 'f161', 'f294', 'f103', 'f223', 'f27', 'f56', 'f278', 'f232', 'f16', 'f54', 'f239', 'f57', 'f285', 'f102', 'f206', 'f26', 'n_f30', 'f287', 'f75', 'f73', 'n_f287', 'f290', 'f12', 'n_f175', 'f264', 'f265', 'f184', 'f249', 'f164', 'f225', 'f240', 'n_f286', 'f252', 'f230', 'n_f20', 'f183', 'f34', 'n_f285', 'f271', 'f13', 'f286', 'n_f26', 'f205', 'f297', 'n_f237', 'n_f106', 'n_f182', 'f222', 'f80', 'f224', 'f134', 'f251', 'f283', 'f3', 'f79', 'n_f90', 'f259', 'f211', 'f219', 'n_f33', 'f21', 'f289', 'n_f289', 'n_f216', 'n_f209', 'n_f49', 'f227', 'n_f14', 'f163', 'n_f290', 'f48']\n",
    "\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-12').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-13',end_date='2017-09-20').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-21',end_date='2017-09-28').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-09-29',end_date='2017-10-06').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-07',end_date='2017-10-14').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-15',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor idx in range(0,5):\\n    Train_DataSet = train_df[train_df.index.isin(list(all_list - DateFold[idx]))].reset_index(drop=True)\\n    Val_DataSet = train_df[train_df.index.isin(DateFold[5])].reset_index(drop=True)\\n    \\n    Normal_Set = Train_DataSet.copy()\\n    N_Fraud_DF = Normal_Set[Normal_Set['Normal']==0]\\n    fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\\n    normal_num = len(Normal_Set[Normal_Set['Normal']==1])\\n    weight = normal_num // fraud_num -1\\n    n_templist = [Normal_Set]\\n    for item in range (0,weight):\\n        n_templist.append(N_Fraud_DF)\\n    Normal_Set =pd.concat(n_templist,ignore_index=True)\\n    post_fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\\n    post_normal_num = len(Normal_Set[Normal_Set['Normal']==1])\\n    print('Normal Weight:',post_fraud_num,post_normal_num)\\n    \\n\\n    Fraud_Set = Train_DataSet.copy()\\n    F_Fraud_DF = Fraud_Set[Fraud_Set['Fraud']==1]\\n    f_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\\n    f_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\\n    fweight = f_normal_num // f_fraud_num -1\\n    f_templist = [Fraud_Set]\\n    for item in range (0,fweight):\\n        f_templist.append(F_Fraud_DF)\\n    Fraud_Set =pd.concat(f_templist,ignore_index=True)\\n    fpost_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\\n    fpost_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\\n    print('Fraud Weight:',fpost_fraud_num,fpost_normal_num)    \\n    \\n    \\n    model_pos,score_pos = model_validation(Normal_Set,Val_DataSet,predictors,'Normal',{})\\n    model_neg,score_neg = model_validation(Fraud_Set,Val_DataSet,predictors,'Fraud',{})\\n    pos_model_list.append(model_pos)\\n    neg_model_list.append(model_neg)\\n    score_posA.append(score_pos)\\n    score_negA.append(score_neg)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_model_list  =[]\n",
    "neg_model_list  =[]\n",
    "score_posA = []\n",
    "score_negA = []\n",
    "\n",
    "'''\n",
    "for idx in range(0,5):\n",
    "    Train_DataSet = train_df[train_df.index.isin(list(all_list - DateFold[idx]))].reset_index(drop=True)\n",
    "    Val_DataSet = train_df[train_df.index.isin(DateFold[5])].reset_index(drop=True)\n",
    "    \n",
    "    Normal_Set = Train_DataSet.copy()\n",
    "    N_Fraud_DF = Normal_Set[Normal_Set['Normal']==0]\n",
    "    fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\n",
    "    normal_num = len(Normal_Set[Normal_Set['Normal']==1])\n",
    "    weight = normal_num // fraud_num -1\n",
    "    n_templist = [Normal_Set]\n",
    "    for item in range (0,weight):\n",
    "        n_templist.append(N_Fraud_DF)\n",
    "    Normal_Set =pd.concat(n_templist,ignore_index=True)\n",
    "    post_fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\n",
    "    post_normal_num = len(Normal_Set[Normal_Set['Normal']==1])\n",
    "    print('Normal Weight:',post_fraud_num,post_normal_num)\n",
    "    \n",
    "\n",
    "    Fraud_Set = Train_DataSet.copy()\n",
    "    F_Fraud_DF = Fraud_Set[Fraud_Set['Fraud']==1]\n",
    "    f_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\n",
    "    f_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\n",
    "    fweight = f_normal_num // f_fraud_num -1\n",
    "    f_templist = [Fraud_Set]\n",
    "    for item in range (0,fweight):\n",
    "        f_templist.append(F_Fraud_DF)\n",
    "    Fraud_Set =pd.concat(f_templist,ignore_index=True)\n",
    "    fpost_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\n",
    "    fpost_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\n",
    "    print('Fraud Weight:',fpost_fraud_num,fpost_normal_num)    \n",
    "    \n",
    "    \n",
    "    model_pos,score_pos = model_validation(Normal_Set,Val_DataSet,predictors,'Normal',{})\n",
    "    model_neg,score_neg = model_validation(Fraud_Set,Val_DataSet,predictors,'Fraud',{})\n",
    "    pos_model_list.append(model_pos)\n",
    "    neg_model_list.append(model_neg)\n",
    "    score_posA.append(score_pos)\n",
    "    score_negA.append(score_neg)\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "Normal Weight: 493124 500930\n",
      "Fraud Weight: 503449 500850\n"
     ]
    }
   ],
   "source": [
    "idx=2\n",
    "\n",
    "Train_DataSet = train_df[train_df.index.isin(list(all_list - DateFold[idx]))].reset_index(drop=True)\n",
    "Val_DataSet = train_df[train_df.index.isin(DateFold[5])].reset_index(drop=True)\n",
    "\n",
    "#Train_DataSet = Train_DataSet[Train_DataSet['mean'] >0.5].reset_index(drop=True)\n",
    "#Val_DataSet = Val_DataSet[Val_DataSet['mean']>0.5].reset_index(drop=True)\n",
    "\n",
    "Normal_Set = Train_DataSet.copy()\n",
    "N_Fraud_DF = Normal_Set[Normal_Set['Normal']==0]\n",
    "fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\n",
    "normal_num = len(Normal_Set[Normal_Set['Normal']==1])\n",
    "weight = normal_num // fraud_num -1\n",
    "print(weight)\n",
    "n_templist = [Normal_Set]\n",
    "for item in range (0,weight):\n",
    "    n_templist.append(N_Fraud_DF)\n",
    "Normal_Set =pd.concat(n_templist,ignore_index=True)\n",
    "post_fraud_num = len(Normal_Set[Normal_Set['Normal']==0])\n",
    "post_normal_num = len(Normal_Set[Normal_Set['Normal']==1])\n",
    "print('Normal Weight:',post_fraud_num,post_normal_num)\n",
    "\n",
    "\n",
    "Fraud_Set = Train_DataSet.copy()\n",
    "F_Fraud_DF = Fraud_Set[Fraud_Set['Fraud']==1]\n",
    "f_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\n",
    "f_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\n",
    "fweight = f_normal_num // f_fraud_num -1\n",
    "f_templist = [Fraud_Set]\n",
    "for item in range (0,fweight):\n",
    "    f_templist.append(F_Fraud_DF)\n",
    "Fraud_Set =pd.concat(f_templist,ignore_index=True)\n",
    "fpost_fraud_num = len(Fraud_Set[Fraud_Set['Fraud']==0])\n",
    "fpost_normal_num = len(Fraud_Set[Fraud_Set['Fraud']==1])\n",
    "print('Fraud Weight:',fpost_fraud_num,fpost_normal_num)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_SUM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors = ['mean', 'n_f7', 'f7', 'f210', 'f238', 'f15', 'f253', 'f5', 'f99', 'f243', 'f82', 'f248', 'f247', 'f84', 'f234', 'f209', 'f106', 'n_NaN_LIST', 'f18', 'f218', 'n_f6', 'f101', 'f85', 'f204', 'f237', 'f81', 'f19', 'f86', 'f31', 'f215', 'f246', 'n_f28', 'f58', 'n_f284', 'f207', 'f53', 'n_f29', 'f178', 'f266', 'f244', 'f216', 'f4', 'f245', 'f55', 'f242', 'n_f244', 'f217', 'f235', 'f105', 'f9', 'f83', 'f233', 'n_f236', 'f262', 'n_f215', 'f17', 'n_f208', 'f236', 'f100', 'f214', 'f98', 'f30', 'n_f238', 'f208', 'n_f245', 'f6', 'f63', 'n_f25', 'f8', 'f263', 'f110', 'f130', 'f250', 'n_f235', 'f11', 'n_f210', 'n_f21', 'f14', 'n_f294', 'f291', 'f241', 'f226', 'f104', 'f10', 'f185', 'f231', 'n_f105', 'f52', 'f284', 'f161', 'f294', 'f103', 'f223', 'f27',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing validation datasets\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrain's auc: 0.953141\tvalid's auc: 0.918661\n",
      "[100]\ttrain's auc: 0.980974\tvalid's auc: 0.955337\n",
      "[150]\ttrain's auc: 0.985333\tvalid's auc: 0.963471\n",
      "[200]\ttrain's auc: 0.988549\tvalid's auc: 0.968093\n",
      "[250]\ttrain's auc: 0.990976\tvalid's auc: 0.971059\n",
      "[300]\ttrain's auc: 0.992618\tvalid's auc: 0.97367\n",
      "[350]\ttrain's auc: 0.993302\tvalid's auc: 0.975483\n",
      "[400]\ttrain's auc: 0.994037\tvalid's auc: 0.976929\n",
      "[450]\ttrain's auc: 0.995124\tvalid's auc: 0.974533\n",
      "[500]\ttrain's auc: 0.995678\tvalid's auc: 0.97359\n",
      "Early stopping, best iteration is:\n",
      "[405]\ttrain's auc: 0.994159\tvalid's auc: 0.97705\n"
     ]
    }
   ],
   "source": [
    "model_neg,score_neg = model_validation(Fraud_Set,Val_DataSet,predictors,'Fraud',{})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model_neg.feature_importance(importance_type='split')\n",
    "feature_name = model_neg.feature_name()\n",
    "# for (feature_name,importance) in zip(feature_name,importance):\n",
    "#     print (feature_name,importance) \n",
    "feature_importance = pd.DataFrame({'feature_name':feature_name,'importance':importance} )\n",
    "feature_importance.to_csv('feature_importance.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(feature_importance.sort_values('importance',ascending=False).head(160)['feature_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
