{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import atecml.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric o validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        model_list = []\n",
    "        \n",
    "        for i in range(0,n_folds):\n",
    "            \n",
    "            val_index = DateFold[5] #始终用最后20%验证            \n",
    "            train_index = list(all_list - DateFold[i])\n",
    "            \n",
    "            y_tra1 = y_train[train_index]\n",
    "            n_sample = y_tra1.shape[0]\n",
    "            n_pos_sample = y_tra1[y_tra1 == 0].shape[0]\n",
    "            n_neg_sample = y_tra1[y_tra1 == 1].shape[0]\n",
    "            print('样本个数：{}; 正样本占{:.2%}; 负样本占{:.2%}'.format(n_sample,\n",
    "                                                   n_pos_sample / n_sample,\n",
    "                                                               n_neg_sample / n_sample))\n",
    "            target = 'label'\n",
    "            temp_df = train_df[train_df.index.isin(train_index)].reset_index(drop=True)\n",
    "            \n",
    "            filter_list = [x for x in temp_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "            filter_list.append(target)\n",
    "            temp_df = temp_df[filter_list]\n",
    "            \n",
    "            fraud_indices = np.array(temp_df[temp_df[target] == 1].index)\n",
    "            normal_indices = np.array(temp_df[temp_df[target] == 0].index)\n",
    "            \n",
    "            number_record_fraud = len(fraud_indices)\n",
    "            number_record_normal = len(normal_indices)\n",
    "            #undersample\n",
    "            random_normal_indices = np.array(np.random.choice(normal_indices,number_record_fraud,replace=False))\n",
    "            #oversample\n",
    "            random_fraud_indices = np.array(np.random.choice(fraud_indices,number_record_normal,replace=True))\n",
    "            # 汇总正、负样本的索引\n",
    "            under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "            over_sample_indices = np.concatenate([normal_indices,random_fraud_indices])\n",
    "            \n",
    "            # 根据汇总的索引提取数据集\n",
    "            #under_sample_data = temp_df.iloc[under_sample_indices,:]\n",
    "            under_sample_data = temp_df.iloc[over_sample_indices,:]\n",
    "            # 在数据集中提取特征、标签数据\n",
    "            x_tra = np.array(under_sample_data.iloc[:,under_sample_data.columns != target])\n",
    "            y_tra = np.array(under_sample_data.iloc[:,under_sample_data.columns == target][target])\n",
    "            \n",
    "            # 检查获取的样本特征、标签数据\n",
    "            #print(x_tra.shape,y_tra.shape)\n",
    "                            \n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            \n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            model_list.append(model)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test,model_list\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    '''\n",
    "    ' 调参范围\n",
    "    'num_leaves':range(35,65,5)\n",
    "    'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7]\n",
    "    'min_child_weight':range(1,6,2)\n",
    "    'max_depth':range(3,10,2),\n",
    "    'subsample':[i/10.0 for i in range(6,10)],正常直接设置为1\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]，正常直接设置为1\n",
    "    'reg_alpha','reg_lambda':[1e-5, 1e-2, 0.1, 1, 2,2.5,3]\n",
    "    '''\n",
    "    def __init__(self,boost_type,boost_round=1000,early_stop=100,pos_weight=1):\n",
    "        self.num_boost_round = boost_round\n",
    "        self.early_stopping_rounds = early_stop\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': boost_type,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_bin': 255,\n",
    "            'max_depth': -1,\n",
    "            'metric': {'auc'},\n",
    "            'min_child_samples': 600,\n",
    "            'min_child_weight': 0.05,\n",
    "            'min_split_gain': 0,\n",
    "            'nthread': 40,\n",
    "            'num_leaves': 80,\n",
    "            'objective': 'binary',\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            #'is_unbalance':'true',\n",
    "            #'scale_pos_weight': pos_weight,\n",
    "            'subsample': 0.85,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'subsample_freq': 1,\n",
    "            'use_missing': 'true',\n",
    "            'verbose' : -1,\n",
    "            }\n",
    "        print(self.params)\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets=lgbval, \n",
    "                          verbose_eval = 50,\n",
    "                          num_boost_round = self.num_boost_round,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "def stack_layer1_result(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        rf_input_list = []\n",
    "        for idx in tqdm(range(len(rf_model_list))):\n",
    "            model = rf_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            rf_input_list.append(pd.DataFrame(_temp_df))\n",
    "        rf_oof_predict= np.array(pd.concat(rf_input_list,ignore_index=True,axis=1).mean(axis=1))    \n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    input_predict = [rf_oof_predict, gbdt_oof_predict, dart_oof_predict] \n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761864, 228142)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练集为第一步build的纬度提升矩阵，并过滤掉unknown标签\n",
    "data = atecml.data.load_train()\n",
    "train_df = data[data['label']!=-1].reset_index(drop=True)\n",
    "\n",
    "#最终预测的测试集为unknown标签\n",
    "val_df = data[data['label']==-1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "predictors = [x for x in data.columns if x not in atecml.data.NOT_FEATURE_COLUMNS2]\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-13').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-14',end_date='2017-09-22').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-23',end_date='2017-10-01').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-10-02',end_date='2017-10-12').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-13',end_date='2017-10-22').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-23',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990006, 230) (990006,) (4725, 230)\n"
     ]
    }
   ],
   "source": [
    "target='label'\n",
    "x_train = np.array(train_df[predictors])\n",
    "y_train = np.array(train_df[target])\n",
    "x_test = np.array(val_df[predictors])\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12122 977884 80.67018643788154\n"
     ]
    }
   ],
   "source": [
    "num_pos = np.sum(train_df[target])  \n",
    "num_neg = x_train.shape[0]- num_pos\n",
    "scale_pos_weight =  num_neg/num_pos\n",
    "print(num_pos,num_neg,scale_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 1000\n",
    "num_early_stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_samples': 600, 'min_child_weight': 0.05, 'objective': 'binary', 'use_missing': 'true', 'verbose': -1, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'max_bin': 255, 'learning_rate': 0.1, 'metric': {'auc'}, 'subsample_for_bin': 200000, 'min_split_gain': 0, 'nthread': 40, 'max_depth': -1, 'num_leaves': 80, 'subsample_freq': 1, 'boosting_type': 'rf', 'subsample': 0.85, 'colsample_bytree': 0.7, 'task': 'train'}\n",
      "样本个数：613958; 正样本占98.77%; 负样本占1.23%\n",
      "0 fold, train 613958, val 228142\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.679846\n",
      "[100]\tvalid_0's auc: 0.690284\n",
      "[150]\tvalid_0's auc: 0.695156\n",
      "[200]\tvalid_0's auc: 0.691843\n",
      "[250]\tvalid_0's auc: 0.694868\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.695424\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "样本个数：621410; 正样本占98.77%; 负样本占1.23%\n",
      "1 fold, train 621410, val 228142\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.588344\n",
      "[100]\tvalid_0's auc: 0.590239\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.626063\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "样本个数：621303; 正样本占98.89%; 负样本占1.11%\n",
      "2 fold, train 621303, val 228142\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.569724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get output of first layer models and construct as input for the second layer          \n",
    "rf_classifier = LGBClassifier(boost_type='rf',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "rf_oof_train, rf_oof_test,rf_model_list = rf_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(rf_oof_train.shape, rf_oof_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbdt_classifier = LGBClassifier(boost_type='gbdt',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "gbdt_oof_train, gbdt_oof_test,gbdt_model_list = gbdt_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(gbdt_oof_train.shape, gbdt_oof_test.shape)  \n",
    "\n",
    "dart_classifier = LGBClassifier(boost_type='dart',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "dart_oof_train, dart_oof_test,dart_model_list = dart_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(dart_oof_train.shape, dart_oof_test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_train = stack_layer1_result(x_train,rf_model_list,gbdt_model_list,dart_model_list)\n",
    "stacked_test = stack_layer1_result(x_test,rf_model_list,gbdt_model_list,dart_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use XGBOOST  as the model of the second layer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = pd.DataFrame(model.predict_proba(x_val))[1]\n",
    "\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "final_model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict_proba(stacked_test)\n",
    "\n",
    "result=pd.DataFrame()\n",
    "result['id'] = val_df['id']\n",
    "result['score'] = pd.DataFrame(test_prediction)[1]\n",
    "result.to_pickle('./reject_inf.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[result.score > 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result.score > 0.8].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle('./reject_inf.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aval_df = atecml.data.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_test = np.array(aval_df[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ax_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_test = stack_layer1_result(ax_test,rf_model_list,gbdt_model_list,dart_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stacked_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = final_model.predict_proba(stacked_test)\n",
    "\n",
    "result=pd.DataFrame()\n",
    "result['id'] = aval_df['id']\n",
    "result['score'] = pd.DataFrame(test_prediction)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./aaa.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
