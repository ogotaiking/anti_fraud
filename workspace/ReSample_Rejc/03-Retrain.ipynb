{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import atecml.data\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BasicModel(object):\n",
    "    \"\"\"Parent class of basic models\"\"\"\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        \"\"\"return a trained model and eval metric o validation data\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        \"\"\"return the predicted result\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_oof(self, x_train, y_train, x_test, n_folds = 5):\n",
    "        \"\"\"K-fold stacking\"\"\"\n",
    "        num_train, num_test = x_train.shape[0], x_test.shape[0]\n",
    "        oof_train = np.zeros((num_train,)) \n",
    "        oof_test = np.zeros((num_test,))\n",
    "        oof_test_all_fold = np.zeros((num_test, n_folds))\n",
    "        aucs = []\n",
    "        model_list = []\n",
    "        \n",
    "        for i in range(0,n_folds):\n",
    "            \n",
    "            val_index = DateFold[5] #始终用最后20%验证            \n",
    "            train_index = list(all_list - DateFold[i])\n",
    "                            \n",
    "            print('{0} fold, train {1}, val {2}'.format(i, len(train_index), len(val_index)))\n",
    "            x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "            x_val, y_val = x_train[val_index], y_train[val_index]\n",
    "            \n",
    "            #Over_sample\n",
    "            #X_resampled, y_resampled = SMOTE().fit_sample(x_tra,y_tra)\n",
    "            #model, auc = self.train(X_resampled, y_resampled, x_val, y_val)\n",
    "            model, auc = self.train(x_tra, y_tra, x_val, y_val)\n",
    "            aucs.append(auc)\n",
    "            model_list.append(model)\n",
    "            oof_train[val_index] = self.predict(model, x_val)\n",
    "            oof_test_all_fold[:, i] = self.predict(model, x_test)\n",
    "        oof_test = np.mean(oof_test_all_fold, axis=1)\n",
    "        print('all aucs {0}, average {1}'.format(aucs, np.mean(aucs)))\n",
    "        return oof_train, oof_test,model_list\n",
    "\n",
    "import lightgbm as lgb\n",
    "class LGBClassifier(BasicModel):\n",
    "    '''\n",
    "    ' 调参范围\n",
    "    'num_leaves':range(35,65,5)\n",
    "    'learning_rate':[0.01,0.05,0.1,0.3,0.5,0.7]\n",
    "    'min_child_weight':range(1,6,2)\n",
    "    'max_depth':range(3,10,2),\n",
    "    'subsample':[i/10.0 for i in range(6,10)],正常直接设置为1\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)]，正常直接设置为1\n",
    "    'reg_alpha','reg_lambda':[1e-5, 1e-2, 0.1, 1, 2,2.5,3]\n",
    "    '''\n",
    "    def __init__(self,boost_type,boost_round=1000,early_stop=100,pos_weight=1):\n",
    "        self.num_boost_round = boost_round\n",
    "        self.early_stopping_rounds = early_stop\n",
    "        self.params = {\n",
    "            'task': 'train',\n",
    "            'boosting_type': boost_type,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_bin': 511,\n",
    "            'max_depth': -1,\n",
    "            'metric': {'auc'},\n",
    "            'min_child_samples': 200,\n",
    "            'min_child_weight': 0.05,\n",
    "            'min_split_gain': 0,\n",
    "            'nthread': 40,\n",
    "            'num_leaves': 80,\n",
    "            'objective': 'binary',\n",
    "            'reg_alpha': 0.01,\n",
    "            'reg_lambda': 0.01,\n",
    "            #'is_unbalance':'true',\n",
    "            'scale_pos_weight': pos_weight,\n",
    "            'subsample': 0.85,\n",
    "            'subsample_for_bin': 200000,\n",
    "            'subsample_freq': 1,\n",
    "            'use_missing': 'true',\n",
    "            'verbose' : -1,\n",
    "            #'device': 'gpu'\n",
    "            }\n",
    "        print(self.params)\n",
    "        \n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('train with lgb model')\n",
    "        lgbtrain = lgb.Dataset(x_train, y_train)\n",
    "        lgbval = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(self.params, \n",
    "                          lgbtrain,\n",
    "                          valid_sets=lgbval, \n",
    "                          verbose_eval = 50,\n",
    "                          num_boost_round = self.num_boost_round,\n",
    "                          early_stopping_rounds = self.early_stopping_rounds)\n",
    "        return model, model.best_score['valid_0']['auc']\n",
    "    \n",
    "    def predict(self, model, x_test):\n",
    "        print('test with lgb model')\n",
    "        return model.predict(x_test, num_iteration=model.best_iteration)\n",
    "\n",
    "def stack_layer1_result(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        rf_input_list = []\n",
    "        for idx in tqdm(range(len(rf_model_list))):\n",
    "            model = rf_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            rf_input_list.append(pd.DataFrame(_temp_df))\n",
    "        rf_oof_predict= np.array(pd.concat(rf_input_list,ignore_index=True,axis=1).mean(axis=1))    \n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    input_predict = [rf_oof_predict, gbdt_oof_predict, dart_oof_predict] \n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict\n",
    "\n",
    "\n",
    "def stack_layer1_result_wo_rf(X_train,rf_model_list,gbdt_model_list,dart_model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        predict_list = []\n",
    "    \n",
    "        gbdt_input_list = []\n",
    "        for idx in tqdm(range(len(gbdt_model_list))):\n",
    "            model = gbdt_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            predict_list.append(_temp_df)\n",
    "            gbdt_input_list.append(pd.DataFrame(_temp_df))\n",
    "        gbdt_oof_predict= np.array(pd.concat(gbdt_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "        \n",
    "        \n",
    "        dart_input_list = []\n",
    "        for idx in tqdm(range(len(dart_model_list))):\n",
    "            model = dart_model_list[idx]\n",
    "            _temp_df = model.predict(X_train,num_iteration=model.best_iteration)\n",
    "            predict_list.append(_temp_df)\n",
    "            dart_input_list.append(pd.DataFrame(_temp_df))\n",
    "        dart_oof_predict= np.array(pd.concat(dart_input_list,ignore_index=True,axis=1).mean(axis=1))\n",
    "    \n",
    "    #input_predict = [ gbdt_oof_predict, dart_oof_predict] \n",
    "    input_predict = predict_list\n",
    "    stacked_predict = np.concatenate([f.reshape(-1, 1) for f in input_predict], axis=1)\n",
    "    \n",
    "    return stacked_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634284, 360447)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle('./train.dat')\n",
    "val_df = atecml.data.load_test()\n",
    "\n",
    "\n",
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS]\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-12').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-13',end_date='2017-09-20').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-21',end_date='2017-09-28').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-09-29',end_date='2017-10-06').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-07',end_date='2017-10-14').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-15',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994731, 297) (994731,) (500538, 297)\n"
     ]
    }
   ],
   "source": [
    "target='Fraud'\n",
    "x_train = np.array(train_df[predictors])\n",
    "y_train = np.array(train_df[target])\n",
    "x_test = np.array(val_df[predictors])\n",
    "print(x_train.shape, y_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13387.0 981344.0 73.30574437887503\n"
     ]
    }
   ],
   "source": [
    "num_pos = np.sum(train_df[target])  \n",
    "num_neg = x_train.shape[0]- num_pos\n",
    "scale_pos_weight =  num_neg/num_pos\n",
    "print(num_pos,num_neg,scale_pos_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boost_round = 1000\n",
    "num_early_stop = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'train', 'verbose': -1, 'metric': {'auc'}, 'min_child_samples': 200, 'learning_rate': 0.1, 'subsample': 0.85, 'reg_alpha': 0.01, 'colsample_bytree': 0.7, 'num_leaves': 80, 'min_split_gain': 0, 'subsample_for_bin': 200000, 'use_missing': 'true', 'max_bin': 511, 'objective': 'binary', 'boosting_type': 'rf', 'scale_pos_weight': 73.30574437887503, 'nthread': 40, 'subsample_freq': 1, 'reg_lambda': 0.01, 'min_child_weight': 0.05, 'max_depth': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.976628\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's auc: 0.977393\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.971846\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.97214\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.974443\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.975312\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.971335\n",
      "[100]\tvalid_0's auc: 0.97329\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.973523\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.971726\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.97518\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.97739301758963, 0.9721404044683699, 0.9753115029988819, 0.9735226908262652, 0.9751803290203458], average 0.9747095889806985\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "# get output of first layer models and construct as input for the second layer          \n",
    "rf_classifier = LGBClassifier(boost_type='rf',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "rf_oof_train, rf_oof_test,rf_model_list = rf_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(rf_oof_train.shape, rf_oof_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'train', 'verbose': -1, 'metric': {'auc'}, 'min_child_samples': 200, 'learning_rate': 0.1, 'subsample': 0.85, 'reg_alpha': 0.01, 'colsample_bytree': 0.7, 'num_leaves': 80, 'min_split_gain': 0, 'subsample_for_bin': 200000, 'use_missing': 'true', 'max_bin': 511, 'objective': 'binary', 'boosting_type': 'gbdt', 'scale_pos_weight': 73.30574437887503, 'nthread': 40, 'subsample_freq': 1, 'reg_lambda': 0.01, 'min_child_weight': 0.05, 'max_depth': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.97971\n",
      "[100]\tvalid_0's auc: 0.98039\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.980665\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.97275\n",
      "[100]\tvalid_0's auc: 0.975489\n",
      "[150]\tvalid_0's auc: 0.976099\n",
      "[200]\tvalid_0's auc: 0.97596\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's auc: 0.976464\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.979149\n",
      "[100]\tvalid_0's auc: 0.980266\n",
      "[150]\tvalid_0's auc: 0.980917\n",
      "[200]\tvalid_0's auc: 0.981002\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's auc: 0.981101\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.976655\n",
      "[100]\tvalid_0's auc: 0.977969\n",
      "[150]\tvalid_0's auc: 0.977931\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.978433\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.977149\n",
      "[100]\tvalid_0's auc: 0.979837\n",
      "[150]\tvalid_0's auc: 0.97997\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.980427\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9806649732393293, 0.9764637703622594, 0.981101293057499, 0.9784325168744948, 0.9804269862502457], average 0.9794179079567658\n",
      "(994731,) (500538,)\n",
      "{'task': 'train', 'verbose': -1, 'metric': {'auc'}, 'min_child_samples': 200, 'learning_rate': 0.1, 'subsample': 0.85, 'reg_alpha': 0.01, 'colsample_bytree': 0.7, 'num_leaves': 80, 'min_split_gain': 0, 'subsample_for_bin': 200000, 'use_missing': 'true', 'max_bin': 511, 'objective': 'binary', 'boosting_type': 'dart', 'scale_pos_weight': 73.30574437887503, 'nthread': 40, 'subsample_freq': 1, 'reg_lambda': 0.01, 'min_child_weight': 0.05, 'max_depth': -1}\n",
      "0 fold, train 500685, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.979504\n",
      "[100]\tvalid_0's auc: 0.981628\n",
      "[150]\tvalid_0's auc: 0.982309\n",
      "[200]\tvalid_0's auc: 0.983305\n",
      "[250]\tvalid_0's auc: 0.984012\n",
      "[300]\tvalid_0's auc: 0.984944\n",
      "[350]\tvalid_0's auc: 0.985014\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's auc: 0.985291\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "1 fold, train 509423, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.972074\n",
      "[100]\tvalid_0's auc: 0.978171\n",
      "[150]\tvalid_0's auc: 0.981177\n",
      "[200]\tvalid_0's auc: 0.98251\n",
      "[250]\tvalid_0's auc: 0.983849\n",
      "[300]\tvalid_0's auc: 0.983923\n",
      "[350]\tvalid_0's auc: 0.984555\n",
      "[400]\tvalid_0's auc: 0.98476\n",
      "[450]\tvalid_0's auc: 0.984623\n",
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's auc: 0.984942\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "2 fold, train 509014, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.980146\n",
      "[100]\tvalid_0's auc: 0.981931\n",
      "[150]\tvalid_0's auc: 0.983364\n",
      "[200]\tvalid_0's auc: 0.983463\n",
      "[250]\tvalid_0's auc: 0.984452\n",
      "[300]\tvalid_0's auc: 0.984629\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's auc: 0.985153\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "3 fold, train 518384, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.976837\n",
      "[100]\tvalid_0's auc: 0.980867\n",
      "[150]\tvalid_0's auc: 0.982885\n",
      "[200]\tvalid_0's auc: 0.983461\n",
      "[250]\tvalid_0's auc: 0.984122\n",
      "[300]\tvalid_0's auc: 0.984423\n",
      "Early stopping, best iteration is:\n",
      "[281]\tvalid_0's auc: 0.984456\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "4 fold, train 499630, val 360447\n",
      "train with lgb model\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tvalid_0's auc: 0.975664\n",
      "[100]\tvalid_0's auc: 0.979936\n",
      "[150]\tvalid_0's auc: 0.981639\n",
      "[200]\tvalid_0's auc: 0.98301\n",
      "[250]\tvalid_0's auc: 0.984377\n",
      "[300]\tvalid_0's auc: 0.984496\n",
      "[350]\tvalid_0's auc: 0.984935\n",
      "[400]\tvalid_0's auc: 0.98474\n",
      "Early stopping, best iteration is:\n",
      "[356]\tvalid_0's auc: 0.985158\n",
      "test with lgb model\n",
      "test with lgb model\n",
      "all aucs [0.9852907631030543, 0.9849423857260965, 0.9851525661130839, 0.9844558947965403, 0.9851582069185786], average 0.9849999633314706\n",
      "(994731,) (500538,)\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = LGBClassifier(boost_type='gbdt',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "gbdt_oof_train, gbdt_oof_test,gbdt_model_list = gbdt_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(gbdt_oof_train.shape, gbdt_oof_test.shape)  \n",
    "\n",
    "dart_classifier = LGBClassifier(boost_type='dart',boost_round=num_boost_round,early_stop=num_early_stop,pos_weight= scale_pos_weight)\n",
    "dart_oof_train, dart_oof_test,dart_model_list = dart_classifier.get_oof(x_train, y_train, x_test)\n",
    "print(dart_oof_train.shape, dart_oof_test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 19:00:50][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  3.25s/it]\n",
      "100%|██████████| 5/5 [00:23<00:00,  4.64s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 19:01:29][Classification: Building Layer-1 Stack] End   ...[Elapsed: 39.64s]\n",
      "[2018-07-03 19:01:29][Classification: Building Layer-1 Stack] Begin ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:08<00:00,  1.60s/it]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-03 19:01:48][Classification: Building Layer-1 Stack] End   ...[Elapsed: 18.76s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stacked_train = stack_layer1_result_wo_rf(x_train,rf_model_list,gbdt_model_list,dart_model_list)\n",
    "stacked_test  = stack_layer1_result_wo_rf(x_test,rf_model_list,gbdt_model_list,dart_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-19629f346add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_f2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_f3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matecml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "_y = pd.DataFrame(stacked_train[n:])[0]\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use XGBOOST  as the model of the second layer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "# split for validation\n",
    "n = int(stacked_train.shape[0] * 0.8)\n",
    "x_tra, y_tra = stacked_train[:n], y_train[:n]\n",
    "x_val, y_val = stacked_train[n:], y_train[n:]\n",
    "model.fit(x_tra,y_tra)\n",
    "y_pred = pd.DataFrame(model.predict_proba(x_val))[1]\n",
    "\n",
    "_f1,_f2,_f3 = atecml.data.accuracy_validation(y_val,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "final_model = XGBClassifier(\n",
    " learning_rate =0.05,\n",
    " n_estimators=200,\n",
    " max_depth=3,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.9,\n",
    " objective= 'binary:logistic',\n",
    " scoring='roc_auc',\n",
    " scale_pos_weight= scale_pos_weight,\n",
    " nthread=40,\n",
    " seed=27)\n",
    "\n",
    "\n",
    "final_model.fit(stacked_train, y_train)\n",
    "test_prediction = final_model.predict_proba(stacked_test)\n",
    "\n",
    "result=pd.DataFrame()\n",
    "result['id'] = val_df['id']\n",
    "result['score'] = pd.DataFrame(test_prediction)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result[result.score > 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result.score > 0.7].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./submit_0703_1800_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
