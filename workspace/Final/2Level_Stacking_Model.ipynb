{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import atecml.data\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#build Models...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import random\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765667, 229064)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_pickle('./01_train.dat')\n",
    "#train_df = atecml.data.load_train()\n",
    "\n",
    "predictors = [x for x in train_df.columns if x not in atecml.data.NOT_FEATURE_COLUMNS2]\n",
    "DateFold={}\n",
    "\n",
    "DateFold[0] = set(atecml.data.filter_date(train_df,start_date='2017-09-05',end_date='2017-09-13').index)\n",
    "DateFold[1] = set(atecml.data.filter_date(train_df,start_date='2017-09-14',end_date='2017-09-22').index)\n",
    "DateFold[2] = set(atecml.data.filter_date(train_df,start_date='2017-09-23',end_date='2017-10-01').index)\n",
    "DateFold[3] = set(atecml.data.filter_date(train_df,start_date='2017-10-02',end_date='2017-10-12').index)\n",
    "DateFold[4] = set(atecml.data.filter_date(train_df,start_date='2017-10-13',end_date='2017-10-22').index)\n",
    "DateFold[5] = list(atecml.data.filter_date(train_df,start_date='2017-10-23',end_date='2017-11-24').index)\n",
    "\n",
    "all_list = set(train_df.index) - set(DateFold[5])\n",
    "len(all_list),len(DateFold[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOE_LIST = joblib.load('./woe_feature.dat')\n",
    "CATE_LIST = WOE_LIST + atecml.data.CATE_FEATURE_LIST\n",
    "\n",
    "#CATE_LIST = atecml.data.CATE_FEATURE_LIST\n",
    "categorical=[]\n",
    "for item in predictors:\n",
    "    if (item in CATE_LIST):\n",
    "        categorical.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_boosting_round = 3000\n",
    "early_stop_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'use_missing' : True,\n",
    "    'is_unbalance': True,\n",
    "    #'scale_pos_weight': 98,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 64,  # we should let it be smaller than 2^(max_depth)\n",
    "    'max_depth': -1,  # -1 means no limit\n",
    "    'min_child_samples': 600,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 255,  # Number of bucketed bin for feature values\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.85,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'min_child_weight': 0.05,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    'reg_alpha': 0.01,  # L1 regularization term on weights\n",
    "    'reg_lambda': 0.1,  # L2 regularization term on weights\n",
    "    'nthread': 40,\n",
    "    'n_estimators': num_boosting_round,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "rf = {\n",
    "    'boosting_type': 'rf',\n",
    "}\n",
    "rf.update(params)\n",
    "\n",
    "dart = {\n",
    "    'boosting_type': 'dart',\n",
    "}\n",
    "dart.update(params)\n",
    "\n",
    "gbdt = {\n",
    "    'boosting_type': 'gbdt',\n",
    "}\n",
    "gbdt.update(params)\n",
    "\n",
    "param_list = [gbdt,dart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.945743\n",
      "[400]\tvalid_0's auc: 0.949167\n",
      "[600]\tvalid_0's auc: 0.949265\n",
      "Early stopping, best iteration is:\n",
      "[578]\tvalid_0's auc: 0.949526\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.927879\n",
      "[400]\tvalid_0's auc: 0.943937\n",
      "[600]\tvalid_0's auc: 0.947421\n",
      "[800]\tvalid_0's auc: 0.949348\n",
      "[1000]\tvalid_0's auc: 0.95029\n",
      "[1200]\tvalid_0's auc: 0.95105\n",
      "[1400]\tvalid_0's auc: 0.951452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 1/15 [01:33<21:44, 93.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1363]\tvalid_0's auc: 0.95159\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.976605\n",
      "[400]\tvalid_0's auc: 0.982568\n",
      "[600]\tvalid_0's auc: 0.985032\n",
      "[800]\tvalid_0's auc: 0.986186\n",
      "[1000]\tvalid_0's auc: 0.986792\n",
      "[1200]\tvalid_0's auc: 0.987327\n",
      "[1400]\tvalid_0's auc: 0.987733\n",
      "[1600]\tvalid_0's auc: 0.988083\n",
      "[1800]\tvalid_0's auc: 0.988363\n",
      "[2000]\tvalid_0's auc: 0.98861\n",
      "[2200]\tvalid_0's auc: 0.988821\n",
      "[2400]\tvalid_0's auc: 0.98897\n",
      "[2600]\tvalid_0's auc: 0.989093\n",
      "[2800]\tvalid_0's auc: 0.989179\n",
      "[3000]\tvalid_0's auc: 0.989333\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989333\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.964536\n",
      "[400]\tvalid_0's auc: 0.973693\n",
      "[600]\tvalid_0's auc: 0.977704\n",
      "[800]\tvalid_0's auc: 0.980106\n",
      "[1000]\tvalid_0's auc: 0.981827\n",
      "[1200]\tvalid_0's auc: 0.982887\n",
      "[1400]\tvalid_0's auc: 0.983846\n",
      "[1600]\tvalid_0's auc: 0.984452\n",
      "[1800]\tvalid_0's auc: 0.98509\n",
      "[2000]\tvalid_0's auc: 0.985588\n",
      "[2200]\tvalid_0's auc: 0.986069\n",
      "[2400]\tvalid_0's auc: 0.986519\n",
      "[2600]\tvalid_0's auc: 0.986795\n",
      "[2800]\tvalid_0's auc: 0.98694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 2/15 [05:07<33:21, 153.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\tvalid_0's auc: 0.987097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2988]\tvalid_0's auc: 0.987099\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.980311\n",
      "[400]\tvalid_0's auc: 0.984805\n",
      "[600]\tvalid_0's auc: 0.986658\n",
      "[800]\tvalid_0's auc: 0.987652\n",
      "[1000]\tvalid_0's auc: 0.988349\n",
      "[1200]\tvalid_0's auc: 0.988765\n",
      "[1400]\tvalid_0's auc: 0.989021\n",
      "[1600]\tvalid_0's auc: 0.989221\n",
      "[1800]\tvalid_0's auc: 0.989399\n",
      "[2000]\tvalid_0's auc: 0.989586\n",
      "[2200]\tvalid_0's auc: 0.989714\n",
      "[2400]\tvalid_0's auc: 0.989817\n",
      "[2600]\tvalid_0's auc: 0.98993\n",
      "[2800]\tvalid_0's auc: 0.990025\n",
      "[3000]\tvalid_0's auc: 0.990102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2975]\tvalid_0's auc: 0.990105\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.970742\n",
      "[400]\tvalid_0's auc: 0.978284\n",
      "[600]\tvalid_0's auc: 0.981194\n",
      "[800]\tvalid_0's auc: 0.982959\n",
      "[1000]\tvalid_0's auc: 0.984237\n",
      "[1200]\tvalid_0's auc: 0.984983\n",
      "[1400]\tvalid_0's auc: 0.985692\n",
      "[1600]\tvalid_0's auc: 0.986303\n",
      "[1800]\tvalid_0's auc: 0.986883\n",
      "[2000]\tvalid_0's auc: 0.987314\n",
      "[2200]\tvalid_0's auc: 0.987692\n",
      "[2400]\tvalid_0's auc: 0.988014\n",
      "[2600]\tvalid_0's auc: 0.988244\n",
      "[2800]\tvalid_0's auc: 0.98841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 3/15 [08:48<35:13, 176.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\tvalid_0's auc: 0.988567\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2988]\tvalid_0's auc: 0.98857\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.981\n",
      "[400]\tvalid_0's auc: 0.985186\n",
      "[600]\tvalid_0's auc: 0.987237\n",
      "[800]\tvalid_0's auc: 0.988354\n",
      "[1000]\tvalid_0's auc: 0.989029\n",
      "[1200]\tvalid_0's auc: 0.98947\n",
      "[1400]\tvalid_0's auc: 0.989763\n",
      "[1600]\tvalid_0's auc: 0.989926\n",
      "[1800]\tvalid_0's auc: 0.990088\n",
      "[2000]\tvalid_0's auc: 0.990242\n",
      "[2200]\tvalid_0's auc: 0.990358\n",
      "[2400]\tvalid_0's auc: 0.99044\n",
      "[2600]\tvalid_0's auc: 0.990485\n",
      "[2800]\tvalid_0's auc: 0.990562\n",
      "[3000]\tvalid_0's auc: 0.990617\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2974]\tvalid_0's auc: 0.990636\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.970222\n",
      "[400]\tvalid_0's auc: 0.978294\n",
      "[600]\tvalid_0's auc: 0.981783\n",
      "[800]\tvalid_0's auc: 0.983356\n",
      "[1000]\tvalid_0's auc: 0.984634\n",
      "[1200]\tvalid_0's auc: 0.985454\n",
      "[1400]\tvalid_0's auc: 0.986138\n",
      "[1600]\tvalid_0's auc: 0.986718\n",
      "[1800]\tvalid_0's auc: 0.987234\n",
      "[2000]\tvalid_0's auc: 0.987618\n",
      "[2200]\tvalid_0's auc: 0.988042\n",
      "[2400]\tvalid_0's auc: 0.988412\n",
      "[2600]\tvalid_0's auc: 0.988683\n",
      "[2800]\tvalid_0's auc: 0.988869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 4/15 [12:57<35:38, 194.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\tvalid_0's auc: 0.989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[3000]\tvalid_0's auc: 0.989\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.979027\n",
      "[400]\tvalid_0's auc: 0.984717\n",
      "[600]\tvalid_0's auc: 0.986864\n",
      "[800]\tvalid_0's auc: 0.988089\n",
      "[1000]\tvalid_0's auc: 0.98888\n",
      "[1200]\tvalid_0's auc: 0.989414\n",
      "[1400]\tvalid_0's auc: 0.989803\n",
      "[1600]\tvalid_0's auc: 0.990064\n",
      "[1800]\tvalid_0's auc: 0.990283\n",
      "[2000]\tvalid_0's auc: 0.99049\n",
      "[2200]\tvalid_0's auc: 0.990621\n",
      "[2400]\tvalid_0's auc: 0.990755\n",
      "[2600]\tvalid_0's auc: 0.990892\n",
      "Early stopping, best iteration is:\n",
      "[2690]\tvalid_0's auc: 0.99095\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.963264\n",
      "[400]\tvalid_0's auc: 0.974869\n",
      "[600]\tvalid_0's auc: 0.979572\n",
      "[800]\tvalid_0's auc: 0.981827\n",
      "[1000]\tvalid_0's auc: 0.983534\n",
      "[1200]\tvalid_0's auc: 0.984524\n",
      "[1400]\tvalid_0's auc: 0.98534\n",
      "[1600]\tvalid_0's auc: 0.986003\n",
      "[1800]\tvalid_0's auc: 0.986595\n",
      "[2000]\tvalid_0's auc: 0.987061\n",
      "[2200]\tvalid_0's auc: 0.987575\n",
      "[2400]\tvalid_0's auc: 0.988071\n",
      "[2600]\tvalid_0's auc: 0.988348\n",
      "[2800]\tvalid_0's auc: 0.988567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 5/15 [16:57<33:55, 203.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\tvalid_0's auc: 0.988881\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2998]\tvalid_0's auc: 0.988892\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.965231\n",
      "[400]\tvalid_0's auc: 0.966899\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's auc: 0.966925\n",
      "starting fit model...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\tvalid_0's auc: 0.958979\n",
      "[400]\tvalid_0's auc: 0.963801\n",
      "[600]\tvalid_0's auc: 0.965406\n",
      "[800]\tvalid_0's auc: 0.966111\n"
     ]
    }
   ],
   "source": [
    "model_list  =[]\n",
    "\n",
    "for idx in tqdm(range(0,15)):\n",
    "    fold_id = idx//3\n",
    "    Train_DataSet = train_df[train_df.index.isin(list(all_list - DateFold[fold_id]))].reset_index(drop=True)\n",
    "    Normal_DF = Train_DataSet[Train_DataSet['label']==0]\n",
    "    Fraud_DF = Train_DataSet[Train_DataSet['label']==1]\n",
    "    \n",
    "    number_record_fraud = len(Fraud_DF)\n",
    "    number_record_normal = len(Normal_DF)\n",
    "    #undersample\n",
    "    random_normal_indices = np.array(np.random.choice(Normal_DF.index,number_record_fraud,replace=False))\n",
    "    filter_list = list(random_normal_indices) + list(Fraud_DF.index)\n",
    "    under_sample_train = Train_DataSet[Train_DataSet.index.isin(filter_list)].reset_index(drop=True)\n",
    "    \n",
    "    Val_DataSet = train_df[train_df.index.isin(DateFold[idx])].reset_index(drop=True)\n",
    "    X_train = under_sample_train[predictors]\n",
    "    y_train = under_sample_train['Fraud']\n",
    "\n",
    "    X_test = Val_DataSet[predictors]\n",
    "    y_test = Val_DataSet['Fraud']\n",
    "    \n",
    "    for item_params in (param_list):\n",
    "        gbm = lgb.LGBMClassifier(**item_params)\n",
    "        print('starting fit model...')\n",
    "        gbm.fit(X_train, y_train, eval_set=[(X_test, y_test)],eval_metric='auc',early_stopping_rounds=early_stop_round,verbose=200)#,categorical_feature=categorical)\n",
    "        model_list.append(gbm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df[train_df.index.isin(DateFold[5])].reset_index(drop=True)\n",
    "val_df1 = val_df.head(180000)\n",
    "val_df2 = val_df[~val_df.index.isin(list(val_df1.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_r_neg=pd.DataFrame()\n",
    "for idx in tqdm(range(0,len(model_list))):\n",
    "    model_neg = model_list[idx]\n",
    "    val_neg = model_neg.predict_proba(val_df[predictors])\n",
    "    val_r_neg[idx] = pd.DataFrame(val_neg)[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pos_mean = val_r_pos.mean(axis=1)\n",
    "neg_mean = val_r_neg.mean(axis=1)\n",
    "_,_,_ = atecml.data.accuracy_validation(val_df['Fraud'],neg_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_result(X_train,model_list):\n",
    "    with atecml.data.timer('Classification: Building Layer-1 Stack'):\n",
    "        input_list = []\n",
    "        for idx in tqdm(range(len(model_list))):\n",
    "            model = model_list[idx]\n",
    "            _temp_df = pd.DataFrame(model.predict_proba(X_train))[1]\n",
    "            input_list.append(pd.DataFrame(_temp_df))\n",
    "        input_predict= np.array(pd.concat(input_list,ignore_index=True,axis=1))\n",
    "    return input_predict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level2_model_list  =[]\n",
    "# use XGBOOST  as the model of the second layer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "\n",
    "for idx in range(0,5):\n",
    "    \n",
    "    Train_DataSet = train_df[train_df.index.isin(list(all_list - DateFold[idx]))].reset_index(drop=True)\n",
    "    Normal_DF = Train_DataSet[Train_DataSet['label']==0]\n",
    "    Fraud_DF = Train_DataSet[Train_DataSet['label']==1]\n",
    "    \n",
    "    number_record_fraud = len(Fraud_DF)\n",
    "    number_record_normal = len(Normal_DF)\n",
    "    #undersample\n",
    "    random_normal_indices = np.array(np.random.choice(Normal_DF.index,number_record_fraud,replace=False))\n",
    "    filter_list = list(random_normal_indices) + list(Fraud_DF.index)\n",
    "    under_sample_train = Train_DataSet[Train_DataSet.index.isin(filter_list)].reset_index(drop=True)\n",
    "    \n",
    "    X_train = Train_DataSet[predictors]\n",
    "    y_train = Train_DataSet['Fraud']\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "                         learning_rate =0.05,\n",
    "                         n_estimators=400,\n",
    "                         max_depth=3,\n",
    "                         min_child_weight=1,\n",
    "                         gamma=0,\n",
    "                         subsample=0.8,\n",
    "                         colsample_bytree=0.9,\n",
    "                         objective= 'binary:logistic',\n",
    "                         scoring='roc_auc',\n",
    "                         scale_pos_weight= 98,\n",
    "                         nthread=40,\n",
    "                         seed=27)\n",
    "    \n",
    "    X_train_level2 = stack_result(X_train,model_list)\n",
    "    model.fit(X_train_level2,y_train)  \n",
    "    level2_model_list.append(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_df2_level2 = stack_result(val_df[predictors],model_list)\n",
    "foo = stack_result(val_df2_level2,level2_model_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= pd.DataFrame(foo).min(axis=1)\n",
    "_,_,_ = atecml.data.accuracy_validation(val_df['Fraud'],y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = atecml.data.load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_level1 = stack_result(test_df[predictors],model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_level2 = stack_result(test_df_level1,level2_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= pd.DataFrame(test_df_level2).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame()\n",
    "result['id'] = test_df['id']\n",
    "result['score'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./0706_03.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df =atecml.data.load_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_df = unknown_df[unknown_df.label==-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "un_level1 = stack_result(unknown_df[predictors],model_list)\n",
    "un_level2 = stack_result(un_level1,level2_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pred= pd.DataFrame(un_level2).min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_pred.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unresult=pd.DataFrame()\n",
    "unresult['id'] = unknown_df['id']\n",
    "unresult['score'] = un_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unresult.to_pickle('./reject_inf.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
